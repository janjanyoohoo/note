# 项目架构

​	<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210122201557.png" alt="image-20210105152642823" style="zoom: 50%;" />	

### 前台主要技术:

​	用户系统    
​		通过Gitee开源的基于Vue的人人开源实现

​	后台管理系统
​		通过Gitee开源的基于Vue的人人开源实现

​		整合ElementUI快速开发

### 后台主要技术:

​	通过SpringBoot 2.1.8实现业务与Rest风格的前后分离开发

​	通过SpringCloud Greenwich.SR3以及 SpringCloud Alibaba 2.1.0实现分布式

​	持久层使用Mybatis-Plus实现,通过逆向工程生成基本代码

### 其他技术

​	通过Radis实现缓存,使用MySQL 8.0作为存储数据库

​	使用SpringSecurity实现用户登录的认证与授权

​	使用SpringCloud Alibaba 的 Nacos作为微服务的注册中心与配置中心

​	使用Fegin实现服务调用,Hystrix作熔断处理,Gateway API服务网关解决跨域与鉴权限流等问题

​	使用ElasticSeach实现检索,RabbitMQ实现消息队列解耦

​	使用阿里云OSS对象存储服务,Docker容器化技术

### 项目结构

```
mall:
├─common            #公共的模块,工具类,常量类,依赖管理;
├─gateway		    #网关路由模块;
├─guli-coupon       #优惠/秒杀相关模块;
├─guli-member       #前台系统会员用户模块;
├─guli-order        #订单模块;
├─guli-product      #商品模块;
├─guli-ware         #仓储服务模块;
├─renren-fast       #后台系统管理模块,基于人人开源;
└─renren-generator  #基于人人开源的逆向工程代码生成器;
```



# Gateway网关

## Route

​	Gateway网关配置路由规则有多种方式 path host  等 

​	[Route规则 文档](https://docs.spring.io/spring-cloud-gateway/docs/2.2.6.RELEASE/reference/html/#configuring-route-predicate-factories-and-gateway-filter-factories)

```yaml
 - id: guli-sys      	#	ID 自定义 推荐服务名  注意缩进
   uri: lb://guli-sys  	# 	lb->负载均衡     guli-sys 调用的服务名
   predicates:     		#	匹配规则
   - Path=/api/**		#	Path 路径匹配	Host 请求头的主机名匹配等规则  注意缩进
   filters:				#	过滤器			
   - RewritePath=/api(?<segment>/?.*), /renren-fast$\{segment}	#请求uri->过滤后的uri格式 此处示例去掉了api
```

## 跨域

​	通过网关服务的配置类 配置跨域规则; [跨域JDK API](https://docs.spring.io/spring-framework/docs/5.0.x/javadoc-api/org/springframework/web/cors/CorsConfiguration.html)  	[Spring Cloud Gateway 跨域文档](https://docs.spring.io/spring-cloud-gateway/docs/2.2.6.RELEASE/reference/html/#cors-configuration)

```java
@Configuration
public class CorsConfig {

    @Bean
    public CorsWebFilter corsFilter() {
        CorsConfiguration config = new CorsConfiguration();
        config.addAllowedMethod("*");
        config.addAllowedOrigin("*");
        config.addAllowedHeader("*");
        config.setAllowCredentials(true);
        /*
        ("/**", config)  允许所有请求跨域
         */
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(new PathPatternParser());
        source.registerCorsConfiguration("/**", config);

        return new CorsWebFilter(source);
    }
}
```

## 负载均衡

​	Gateway通过**Route指定uri 为 lb 会自动进行负载均衡;** 

​	可以搭配nginx做负载均衡与动静分离

# Nacos

## 配置中心

​	在SpringBoot项目中, 通过**bootstrap**.properties/bootstrap.yml 文件指定nacos配置中心信息, **springboot启动时,会先加载bootstrap文件再加载application文件,然后读取配置中心文件替换相同的配置内容;**

```xml
<groupId>com.alibaba.cloud</groupId>
<artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>
```

```properties
# 服务名,在nacos中注册的名字, 默认配置文件的文件名前缀
spring.application.name=guli-product	
# Nacos注册中心 地址 ip:端口
spring.cloud.nacos.discovery.server-addr=81.70.205.65:8848
# Nacos配置中心 地址 ip:端口 
spring.cloud.nacos.config.server-addr=81.70.205.65:8848

# 基本配置文件  默认ID: 服务名.properties
spring.cloud.nacos.config.namespace=5156e88b-f2eb-4546-86ee-1e573b7897b7	#nacos配置中心命名空间id
spring.cloud.nacos.config.group=dev											#nacos配置中心的group分组信息

# 多个配置文件按此格式三个一组配置 索引 从0开始
spring.cloud.nacos.config.ext-config[0].data-id=mybatis.yml			#data-id=nacos中文件名字
# 文件分组
spring.cloud.nacos.config.ext-config[0].group=dev					#文件所在的分组
# 动态刷新
spring.cloud.nacos.config.ext-config[0].refresh=true				#是否开启配置文件的动态刷新,修改配置文件可以感知

```



## 注册中心

​	SpringCloud支持许多注册中心,nacos注册中心是alibaba的组件, 在服务的配置文件中,指定nacos注册中心地址及端口号,即可将服务注册到nacos,被其他服务调用; 

### 服务注册

​	`@EnableDiscoveryClient` 注解需要开启服务注册,否则配置了nacos信息也不会注册到nacos

```xml
<groupId>com.alibaba.cloud</groupId>
<artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>
```

```properties
spring.application.name=guli-product
# Nacos注册中心
spring.cloud.nacos.discovery.server-addr=81.70.205.65:8848 	#此配置也可以配置在注册中心中
```

### 服务调用

​	`@EnableFeginClients`开启当前服务的服务调用,可以调用在nacos中注册了的其他服务;

​	`@FeginClent("被调用服务名")`调用某某服务需要编写接口,声明注解; 

```java
@FeignClient("guli-search") 			//nacos中注册的服务名
public interface SearchClient {			//接口
    @PostMapping("/search/up/product")  //映射路径需要完整路径
    R upProduct(@RequestBody List<SkuEsInfoTo> skuEsInfoTo);	//被调用的方法声明信息,需要一致
}
```



# ElasticSearch检索服务

ElasticSearch是一个搜索和分析引擎：

- ElasticSearch文检索功能比MySQL强大
- 性能更好，因为ES将数据**存到内存**，且天然支持分布式，不必担心内存不够的问题

## ES JAVA  API 案例

------

### RestHighLevelClien

- **bulk** hui

  ```java
  client.bulk(BulkRequest, SearchConfig.COMMON_OPTIONS);   	//批处理保存 参数1 BulkRequest
  ```

- **search**

  ```java
  client.search(SearchRequest, SearchConfig.COMMON_OPTIONS);   //搜索  参数1 SearchRequest
  ```

- **index**

  ```java
  client.index(IndexRequest, SearchConfig.COMMON_OPTIONS);  	//单数据保存 参数1 IndexRequest
  ```

- 其他方法  异步等;

#### 配置

```java
@Configuration
public class SearchConfig {
// 	ES的通用配置信息
    public static final RequestOptions COMMON_OPTIONS;
    
    static {
        RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();
//		请求头 定制信息配置
//        builder.addHeader("Authorization", "Bearer " + TOKEN);
//        builder.setHttpAsyncResponseConsumerFactory(
//                new HttpAsyncResponseConsumerFactory
//                        .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024));
        COMMON_OPTIONS = builder.build();
    }
    
//	注入ES操作客户端
    @Bean
    public RestHighLevelClient getRestHighLevelClient(){
        RestHighLevelClient client = new RestHighLevelClient(
                RestClient.builder(
//	支持配置多个HttpHost  需要关闭client.close();  指定ES的端口号与ip 请求方式http
                        new HttpHost("47.116.32.112", 9200, "http")));
        return client;
    }
}
```

### IndexRequest 与批处理

- IndexRequest 单条数据的保存
- BulkRequest 批量数据保存, 通过add()方法 添加IndexRequest 对象;

```java
 @Override
    public Boolean up(List<SkuEsInfoTo> skuEsInfoTo) {
        //封装请求信息  Bulk批处理  BulkRequest封装批处理IndexRequest内容 , 保存单条信息则IndexRequest即可
        BulkRequest bulkRequest = new BulkRequest();
        skuEsInfoTo.stream().forEach(obj->{
            //构建单条信息 IndexRequest
            IndexRequest indexRequest = new IndexRequest(EsConstant.PRODUCT_INDEX);
            indexRequest.id(obj.getSkuId().toString());
            indexRequest.source(JSON.toJSONString(obj), XContentType.JSON);
            //通过add方法组合单个IndexRequest组成批处理
            bulkRequest.add(indexRequest);
        });

        //try捕获异常情况 
        BulkResponse bulk = null;
        try {
            bulk = client.bulk(bulkRequest, SearchConfig.COMMON_OPTIONS);
        } catch (IOException e) {
            log.error("ES批量上架异常{}",e.getMessage());
        }
        
        //TODO 根据ES返回值判断保存是否有出现异常
        boolean b = bulk.hasFailures();
        return b;
    }
```

### SearchRequest查询

- **SearchRequest**

  ```java
  SearchRequest searchRequest = new SearchRequest(new String[]{"mallproduct"},searchSourceBuilder);
  //参数1 索引,支持一个数组      参数2 构建好的SearchSourceBuilder 查询对象
  ```

- **SearchSourceBuilder**   构建条件的最终组合

  ```java
  SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
  ```

  - query

    ```
     BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
     searchSourceBuilder.query(boolQueryBuilder);
    ```

  - aggregation

    ```java
    searchSourceBuilder.aggregation(aggs);  //聚合信息  nested子聚合也同样方式
    ```

  - from

    ```java
    searchSourceBuilder.from(0)  //从第几个开始查询
    ```

  - size

    ```java
    searchSourceBuilder.size(10)  //分页大小
    ```

  - sort

    ```java
    searchSourceBuilder.sort("排序属性",排序方式ASC/DESC);
    ```

  - highlighter

    ```java
    searchSourceBuilder.highlighter(hb);
    ```

- **BoolQueryBuilder**   组合条件查询构建

  ```java
   BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
  ```

  - must

    ```java
     boolQueryBuilder.must(QueryBuilders.matchQuery("brandName",seatchParams.getKeyword()));
    ```

  - filter

    ```java
     boolQueryBuilder.filter(QueryBuilders.termsQuery("brandId",seatchParams.getBrandId()));
    ```

- **NestedQueryBuilder**  嵌入式属性构建

  - ```java
    NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery("attrs",nestedBool, ScoreMode.None);
    //attrs 嵌入式属性path    nestedBool:已组合的条件    ScoreMode.None 评分方式
    ```

- **HighlightBuilder**   高亮字段

  ```java
   HighlightBuilder hb = new HighlightBuilder();    
  ```

  - field /  preTags  / postTags

    ```java
      hb.field("es属性名");        //需要高亮的属性
      hb.preTags("<b style='color:red'>");    //高亮前缀
      hb.postTags("</b>");					//高亮后缀
    ```

- **QueryBuilders** 工具类 构建Query查询

  - boolQuery( )   组合查询

    ```java
     BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
     boolQueryBuilder.filter(QueryBuilders.termQuery("es属性名",val));   //val格式参考参数列表
    ```

  - termQuery( )  精确匹配

    ```java
     boolQueryBuilder.filter(QueryBuilders.termQuery("es属性名",val));   //val格式参考参数列表
    ```

  - matchQuery( )  分词匹配

    ```java
     boolQueryBuilder.must(QueryBuilders.matchQuery("es属性名",val));   //val格式参考参数列表
    ```

  - rangeQuery( )  区间匹配

    ```java
     boolQueryBuilder.filter(QueryBuilders.rangeQuery("es属性名").gte(1).lte(10));  //get大于  lte小于
    ```

  - nestedQuery( )  嵌入式属性查询

    ```java
    BoolQueryBuilder nestedBool = QueryBuilders.boolQuery(); 
    nestedBool.must(QueryBuilders.termsQuery("attrs.attrValue",attrs));  // 嵌入式属性.嵌入式属性的属性
    NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery("attrs",nestedBool, ScoreMode.None);
    //attrs 嵌入式属性path    nestedBool:已组合的条件    ScoreMode.None 评分方式
    ```

- **TermsAggregationBuilder **    聚合

  - terms     聚合方式 精确匹配
  - subAggregation   子聚合,参数是另一个普通聚合

  ```java
  //构建聚合  指定名 与 field被聚合属性  terms方式  size保留的数量
  TermsAggregationBuilder brand_agg = AggregationBuilders.terms("brand_agg").size(10).field("brandId");
  //subAggregation构建子聚合
          brand_agg.subAggregation(AggregationBuilders.terms("brand_name_agg").size(10).field("brandName"));
          brand_agg.subAggregation(AggregationBuilders.terms("brand_id_agg").size(10).field("brandImg"));
          searchSourceBuilder.aggregation(brand_agg);
  ```

- NestedAggregationBuilder   嵌入式聚合

  ```java
  //构建嵌入式聚合  指定 聚合名 与 path
  NestedAggregationBuilder nested = AggregationBuilders.nested("attr_agg", "attrs");  
  //Terms 聚合 与普通聚合相同  terms方式  field聚合的属性   size保留的数量
  TermsAggregationBuilder attr_id_agg = AggregationBuilders.terms("attr_id_agg").size(10).field("attrs.attrId");
  // 子聚合  与 普通聚合相同
  attr_id_agg.subAggregation(AggregationBuilders.terms("attr_value_agg").size(10).field("attrs.attrValue"));
  attr_id_agg.subAggregation(AggregationBuilders.terms("attr_name_agg").size(10).field("attrs.attrName"));
  //将外层的聚合attr_id_agg 放入 嵌入式聚合nested中; 作为nested的子聚合; nested未直接做聚合,而是子聚合与子子聚合完成
  nested.subAggregation(attr_id_agg);
  ```

  

```java
    /**
     * 封装search条件
     */
    public SearchRequest getSearch(SeatchParams seatchParams){
        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
        /*
            品牌名  keyword匹配
         */
        if (!StringUtils.isEmpty(seatchParams.getKeyword())){
            boolQueryBuilder.must(QueryBuilders.matchQuery("brandName",seatchParams.getKeyword()));
        }
        /*
            分类
         */
        if(seatchParams.getCatalog3Id()!=null){
            boolQueryBuilder.filter(QueryBuilders.termQuery("catalogId",seatchParams.getCatalog3Id()));
        }
        /*
            库存
         */
        if(seatchParams.getHasStock()!=null){
            boolQueryBuilder.filter(QueryBuilders.termQuery("hasStock",seatchParams.getHasStock()));
        }
        /*
            品牌查询
         */
        if (seatchParams.getBrandId()!=null && seatchParams.getBrandId().size()>0){
            boolQueryBuilder.filter(QueryBuilders.termsQuery("brandId",seatchParams.getBrandId()));
        }
        /*
            关键词高亮
         */
        if(!StringUtils.isEmpty(seatchParams.getKeyword())){
            HighlightBuilder hb = new HighlightBuilder();
            hb.field("brandName");
            hb.preTags("<b style='color:red'>");
            hb.postTags("</b>");
            searchSourceBuilder.highlighter(hb);
        }

        /*
          价格区间
        */
        if(!StringUtils.isEmpty(seatchParams.getSkuPrice())){
            String[] price = seatchParams.getSort().split("_");
            if (price.length>1){
                boolQueryBuilder.filter(QueryBuilders.rangeQuery("range").gte(price[0]).lte(price[1]));
            }else{
                /*
                 * 只有一个价格查询, 判断是 最大值 / 最小值
                 */
                if(seatchParams.getSkuPrice().startsWith("_")){
                    boolQueryBuilder.filter(QueryBuilders.rangeQuery("range").lte(price[0]));
                }else{
                    boolQueryBuilder.filter(QueryBuilders.rangeQuery("range").gte(price[0]));
                }
            }
        }
        /*
            nested 嵌入式属性查询  attr
         */
        if(seatchParams.getAttrs()!=null && seatchParams.getAttrs().size()>0){
            /*
              每一个嵌入式属性查询必须都得生成一个nested查询,需要写一个单独的 QueryBool , 放入到 boolQuery.filter
             */
            for (String attr : seatchParams.getAttrs()) {
                /*
                    attr格式 : attrs=1_5寸:8寸&attrs=2_16G:8G 切割 0为id 1为属性
                 */
                String[] attrId = attr.split("_");
                String[] attrs = attrId[1].split(":");
                BoolQueryBuilder nestedBool = QueryBuilders.boolQuery();
                nestedBool.must(QueryBuilders.termQuery("attrs.attrId",attrId[0]));
                nestedBool.must(QueryBuilders.termsQuery("attrs.attrValue",attrs));
                NestedQueryBuilder nestedQueryBuilder = QueryBuilders.nestedQuery("attrs",nestedBool, ScoreMode.None);
                boolQueryBuilder.filter(nestedQueryBuilder);
            }
        }
        searchSourceBuilder.query(boolQueryBuilder);
        /*
            聚合查询
         */
        TermsAggregationBuilder brand_agg = AggregationBuilders.terms("brand_agg").size(10).field("brandId");
        brand_agg.subAggregation(AggregationBuilders.terms("brand_name_agg").size(10).field("brandName"));
        brand_agg.subAggregation(AggregationBuilders.terms("brand_id_agg").size(10).field("brandImg"));
        searchSourceBuilder.aggregation(brand_agg);

        TermsAggregationBuilder catalog_agg = AggregationBuilders.terms("catalog_agg").size(10).field("catalogId");
        catalog_agg.subAggregation(AggregationBuilders.terms("catalog_name_agg").size(10).field("catalogName"));
        searchSourceBuilder.aggregation(catalog_agg);

        NestedAggregationBuilder nested = AggregationBuilders.nested("attr_agg", "attrs");
        TermsAggregationBuilder attr_id_agg = AggregationBuilders.terms("attr_id_agg").size(10).field("attrs.attrId");
        attr_id_agg.subAggregation(AggregationBuilders.terms("attr_value_agg").size(10).field("attrs.attrValue"));
        attr_id_agg.subAggregation(AggregationBuilders.terms("attr_name_agg").size(10).field("attrs.attrName"));
        nested.subAggregation(attr_id_agg);
        searchSourceBuilder.aggregation(nested);

        /*
            排序
         */
        if(!StringUtils.isEmpty(seatchParams.getSort())){
            String sort = seatchParams.getSort();
            String[] s = sort.split("_");
            SortOrder so = s[1].equals("asc")? SortOrder.ASC: SortOrder.DESC;
            searchSourceBuilder.sort(s[0],so);
        }
        /*
            分页
         */
        searchSourceBuilder.from(seatchParams.getPageNum());
        searchSourceBuilder.size(10);
        SearchRequest searchRequest = new SearchRequest(new String[]{"mallproduct"},searchSourceBuilder);
        System.out.println(searchSourceBuilder.toString());


        return searchRequest;
    }

```

### SearchResponse结果解析

- **SearchResponse** 基本信息

  ```java
  response.getHits().getHits();   //获取命中的数据集合
  hit.getSourceAsString();       //命中的数据中 我们的数据 非元数据  通过JSON解析
  JSON.parseObject(sourceAsString, to.class);
  
  hit.getHighlightFields().get("brandName");  //获取高亮属性
  response.getHits().getTotalHits().value;   //获取总数
  
  ```

- **聚合信息**   ParsedStringTerms等类型需要结合debug查看返回值类型修改正确

  ```java
  ParsedLongTerms brandAgg = response.getAggregations().get("brand_agg");  //获取聚合  指定聚合的名
  List<? extends Terms.Bucket> buckets = brandAgg.getBuckets();//获取聚合的桶信息,其中子聚合, 如果没有子聚合忽略此步
  
  for (Terms.Bucket bucket : buckets) {
  	bucket.getKeyAsString();     //获取当前brand_agg的 key值
      ParsedStringTerms brandNameAgg = bucket.getAggregations().get("brand_name_agg");   	//获取brand_agg的子聚合
      brandNameAgg.getBuckets().get(0).getKeyAsString();  //brand_name_agg的key
      ParsedStringTerms brandIdAgg = bucket.getAggregations().get("brand_id_agg");		//获取brand_agg的子聚合
     brandIdAgg.getBuckets().get(0).getKeyAsString();		//brand_id_agg的key
  }
  ```

- **嵌入式聚合信息**   ParsedLongTerms等类型需要结合debug查看返回值类型修改正确

  ```java
  // getAggregations.get("attr_agg"); 获取指定的嵌入式聚合
  ParsedNested attrAgg = response.getAggregations().get("attr_agg");
  // 获取嵌入式聚合的子聚合
  ParsedLongTerms attrIdAgg = attrAgg.getAggregations().get("attr_id_agg");
  for (int i = 0; i < attrIdAgg.getBuckets().size(); i++) {
      // 获取 子聚合的桶 根据索引索取  ps:有多个子聚合的时候
      Terms.Bucket bucket = attrIdAgg.getBuckets().get(i);
      // 获取桶的子子聚合
      ParsedStringTerms attr_value_agg = bucket.getAggregations().get("attr_value_agg");
      ParsedStringTerms attr_name_agg = bucket.getAggregations().get("attr_name_agg");
      // 获取当前子聚合的key
      attrIdAgg.getBuckets().get(i).getKeyAsString();
      // 当前子子聚合的key
      attr_name_agg.getBuckets().get(0).getKeyAsString();
      attr_value_agg.getBuckets().get(0).getKeyAsString();
  }
  ```

  

```java
   /**
     * 解析result
     * @param response  search的response新信息
     * @return  页面vo
     */
    public SearchResult getResult(SearchResponse response,SeatchParams seatchParams){
        SearchResult result = new SearchResult(); //自定义的vo类

        /*
            查询到的全部商品信息 商品栏  高亮
         */
        SearchHit[] hits = response.getHits().getHits();
        List<SkuEsInfoTo> list = new ArrayList<>();
        for (SearchHit hit : hits) {
            SkuEsInfoTo sku = new SkuEsInfoTo();
            String sourceAsString = hit.getSourceAsString();
            //属性基本信息
            SkuEsInfoTo skuInfo = JSON.parseObject(sourceAsString, SkuEsInfoTo.class);
            if(!StringUtils.isEmpty(seatchParams.getKeyword())){
                //获取高亮字段,只有一个高亮字段获取[0]
                HighlightField highlightField = hit.getHighlightFields().get("brandName");
                skuInfo.setSkuTitle(highlightField.getFragments()[0].string());
            }
            list.add(skuInfo);
        }
        result.setProducts(list);
            /*
            分页
         */
        Long value = response.getHits().getTotalHits().value;

        result.setTotal(value);
        Long totalPage = value%10==0?value/10:value/10+1;
        result.setTotalPages(Integer.parseInt(totalPage.toString()));
        result.setPageNum(seatchParams.getPageNum());
        /*
            总页数直接封装给前台
         */
        for (int i = 1; i <= Integer.parseInt(totalPage.toString()); i++) {
            result.getPageNavs().add(i);
        }


        /*
            brand聚合信息
         */
        List<SearchResult.BrandVo> brands = new ArrayList<>();
        ParsedLongTerms brandAgg = response.getAggregations().get("brand_agg");
        List<? extends Terms.Bucket> buckets = brandAgg.getBuckets();
        for (Terms.Bucket bucket : buckets) {
            SearchResult.BrandVo brandVo = new SearchResult.BrandVo();
            brandVo.setBrandId(Long.parseLong(bucket.getKeyAsString()));
            ParsedStringTerms brandNameAgg = bucket.getAggregations().get("brand_name_agg");
            brandVo.setBrandName(brandNameAgg.getBuckets().get(0).getKeyAsString());
            ParsedStringTerms brandIdAgg = bucket.getAggregations().get("brand_id_agg");
            brandVo.setBrandImg(brandIdAgg.getBuckets().get(0).getKeyAsString());
            brands.add(brandVo);
        }
        result.setBrands(brands);
        /*
            catalog 聚合信息
         */
        List<SearchResult.CatalogVo> catalogVos = new ArrayList<>();
        ParsedLongTerms catalogAgg = response.getAggregations().get("catalog_agg");
        List<? extends Terms.Bucket> cateBuckets = catalogAgg.getBuckets();
        for (Terms.Bucket cateBucket : cateBuckets) {
            SearchResult.CatalogVo catalogVo = new SearchResult.CatalogVo();
//            ParsedStringTerms catalogIdAgg = cateBucket.getAggregations().get("catalog_id_agg");
//            String keyAsString = catalogIdAgg.getBuckets().get(0).getKeyAsString();
            catalogVo.setCatalogId(Long.parseLong( cateBuckets.get(0).getKeyAsString()));
            ParsedStringTerms catalogNameAgg = cateBucket.getAggregations().get("catalog_name_agg");
            catalogVo.setCatalogName(catalogNameAgg.getBuckets().get(0).getKeyAsString());
            catalogVos.add(catalogVo);
        }
        result.setCatalogs(catalogVos);
        /*
            attr_agg 嵌入式对象聚合信息
         */
        List<SearchResult.AttrVo> attrVos = new ArrayList<>();
        ParsedNested attrAgg = response.getAggregations().get("attr_agg");
        ParsedLongTerms attrIdAgg = attrAgg.getAggregations().get("attr_id_agg");

        for (int i = 0; i < attrIdAgg.getBuckets().size(); i++) {
            Terms.Bucket bucket = attrIdAgg.getBuckets().get(i);
            SearchResult.AttrVo attrVo = new SearchResult.AttrVo();
            ParsedStringTerms attr_value_agg = bucket.getAggregations().get("attr_value_agg");
            ParsedStringTerms attr_name_agg = bucket.getAggregations().get("attr_name_agg");
            attrVo.setAttrId(Long.parseLong(attrIdAgg.getBuckets().get(i).getKeyAsString()));
            attrVo.setAttrName(attr_name_agg.getBuckets().get(0).getKeyAsString());
            List<String> list1 = new ArrayList<>();
            list1.add(attr_value_agg.getBuckets().get(0).getKeyAsString());
            attrVo.setAttrValue(list1);
            attrVos.add(attrVo);
        }
        result.setAttrs(attrVos);
        return result;
    }
```



# Nginx反向代理

### 概念

反向代理: 代理服务器,隐藏服务器的信息
正向代理: 代理客户端,隐藏客户端的信息;

### 通过Nginx反向代理负载均衡代理 网关Gateway

nginx配置上游服务器,配置匹配规则转发给上游服务器; nginx代理时会丢掉很多信息包括 host,cookie等信息,需要单独配置

### frp内网穿透

通过配置内网穿透,将本地服务映射到公网给服务器调用;

```
./frps -c ./frps.ini
```

## Nginx 动静分离

​	将所有static开头的请求全部放到nginx中,由nginx直接返回; 

​	放到nginx的html下 index- > css,js等

​	配置nginx的访问规则即可;

### root与alias

​	重点是理解alias与root的区别，root与alias主要区别在于nginx如何解释location后面的uri，这使两者分别以不同的方式将请求映射到服务器文件上。

　　alias（别名）是一个目录别名。

```
　　　　　　location /123/abc/ {

　　　　　　　　root /ABC;
　　　　　　}
　　　　　　当请求http://qingshan.com/123/abc/logo.png时，会返回 /ABC/123/abc/logo.png文件，即用/ABC 加上 /123/abc。
```

​		root（根目录）是最上层目录的定义。

```
　　　　　　location /123/abc/ {

　　　　　　　　alias /ABC;
　　　　　　}
　　　　　　当请求http://qingshan.com/123/abc/logo.png时，会返回 /ABC/logo.png文件，即用/ABC替换 /123/abc。
```

​	静态文件的匹配规则应该优先于 /  否则无法正确查找静态文件;

```
server {
    listen       80;
    server_name  47.116.32.112;

    #charset koi8-r;
    #access_log  /var/log/nginx/log/host.access.log  main;
	
	location  /static/ {
       root   /usr/share/nginx/html;
       
    }
    
    location / {
        proxy_pass http://mallGateway;
        proxy_set_header Host $host;	 
        # root   /usr/share/nginx/html;
        # index  index.html index.htm;
    }
}
```



# 性能压测

## 性能指标

​	**响应时间**:请求发起到服务端返回的时间

​	**HPS**:每秒点击数

​	**TPS**:每秒交易(事务)数

​	**QPS**:每秒查询数

​	**最大响应时间**: 发出请求到返回的最大时间

​	**最少响应时间**:发出请求到返回的最小时间

​	**90%响应时间**:按所有用户的响应时间排序,第90%用户的响应时间;

​	性能测试关注三个指标:

- 吞吐量 : TPS,QPS..
- 响应时间 
- 错误率

## Apache JMeter工具

​	jdk8 以上版本使用

### 影响性能因素

​	数据库, 中间件tomcat,nginx, 网络和操作系统等

​	**首先应该考虑当前程序属于CPU密集型(大量的计算)还是IO密集型()**

### JMetr Adres Already in use 错误解决

windows 本身提供的端口访问机制的问题。
Windows 提供给 TCP/I 链接的端口为 1024-5000，并且要四分钟来循环回收他们。就导致
我们在短时间内跑大量的请求时将端口占满了。

1.cmd 中，用 regdit 命令打开注册表

2.在 HKEY_LOCAL_MACHINE\SYTEM\CurentControlSet\Services\Tcpi\Parmetrs 下，

​	1 .右击 parmetrs，添加一个新的 DWORD，名字为 MaxUserPot
​	2 .然后双击 MaxUserPot，输入数值数据为 6534，基数选择十进制（如果是分布式运行的话，控制机器和负载机器都需要这样操作哦）

3. 修改配置完毕之后记得重启机器才会生效
   htps:/suport.microsft.com/zh-cn/help/196271/when-you-try-tocnect-from-tcp-orts-grea
   ter-than-50-you-recive-t
   TCPTimedWaitDelay：30

## 监控指标

#### 中间件指标

- 中间件越多，性能损失越大，大多都损失在网络交互了； 
- 当前正在运行的线程数不能超过设定的最大值。一般情况下系统性能较好的情况下，线 程数最小值设置 50 和最大值设置 200 比较合适。
- 当前运行的 JDBC 连接数不能超过设定的最大值。一般情况下系统性能较好的情况下， JDBC 最小值设置 50 和最大值设置 200 比较合适。
- ＧＣ频率不能频繁，特别是 FULL GC 更不能频繁，一般情况下系统性能较好的情况下，
  JVM最小堆大小和最大堆大小分别设置 1024M比较合适。

#### 数据库指标

- SQL 耗时越小越好，一般情况下微秒级别。 

- 命中率越高越好，一般情况下不能低于 95%。

- 锁等待次数越低越好，等待时间越短越好

  #### 业务

- Db（MySQL 优化） 

- 模板的渲染速度（缓存）

- 静态资源

# JVM内存模型

## 堆

所有的对象实例以及数组都要在堆上分配。堆是垃圾收集器管理的主要区域，也被称为“GC 堆”；也是我们优化最多考虑的地方。 堆可以细分为： 

- **新生代** 

- **Eden** 空间 

- **From** **Survivor** 空间 

- **To** **Survivor** 空间

- **老年代**

- 永久代/元空间 

  Java8 以前永久代，受 jvm 管理，java8 以后元空间，直接使用物理内存。因此，
  **默认情况下，元空间的大小仅受本地内存限制。**

  ### GC垃圾回收机制

​	首先对象存入Eden,如果Eden放的下则分配内存

​	Eden放不下则进行一次minGC 将Eden中的不使用的对象清理,部分对象放入 幸存者区S1 S0

​	GC后还是放不下,放到老年代, 老年代放得下则分配内存

​	老年代放不下则进行老年代FullGC(耗时,影响性能); GC后放得下则分配内存,

​	GC后还是放不下则OOM报错

​	Eden转入S1 S0的对象,如果S1 S0放不下则转入老年代

​	S1 S0中的对象,在每次minGC后都会年纪+1,达到一定年纪会转入老年代中;

​	新对象首先放入Eden, 老年代中放的都死存在时间久了的和大的对象

​	<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210122201621.png" alt="image-20210114190453115" style="zoom:50%;" />

​	

​	<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210122201623.png" alt="image-20210114190534155" style="zoom: 67%;" />

## jconsole与jvisualvm性能监控工具

​	Jdk 的两个小工具 **jconsole**、**jvisualvm**（升级版的 jconsole）;通过命令行启动，可监控本地和 远程应用。远程应用需要配置

#### jconsole与**jvisualvm**启动

​	在cmd中输入 **jconsole** 或 **jvisualvm**即可启动

#### jvisualvm功能

监控内存泄露，跟踪垃圾回收，执行时内存、cpu 分析，线程分析

网址 https://visualvm.github.io/pluginscenters.html jvisualvm插件查询对应jdk版本地址

- **运行**：正在运行的 
- **休眠**：sleep 
- **等待**：wait 
- **驻留**：线程池里面的空闲线程
- **监视**：阻塞的线程，正在等待锁

## JVM分析&调优

	jvm调优，调的是稳定，并不能带给你性能的大幅提升。服务稳定的重要性就不用多说了， 保证服务的稳定，gc 永远会是 Java 程序员需要考虑的不稳定因素之一。复杂和高并发下的 服务，必须保证每次 gc 不会出现性能下降，各种性能指标不会出现波动，gc 回收规律而且 干净，找到合适的 jvm设置。Full gc 最会影响性能，根据代码问题，避免 full gc 频率。可以 适当调大年轻代容量，让大对象可以在年轻代触发 yong gc，调整大对象在年轻代的回收频次，尽可能保证大对象在年轻代回收，减小老年代缩短回收时间；



# 缓存与分布式锁

部分数据存储在缓存中,数据库仅做数据落盘持久化的工作;

#### 哪些数据放在缓存中

- 及时性,数据一致性要求不高的
- 访问量大且更新频率不高的;读取多写入少

#### 内存堆外溢出 OutOfDirectMemoryError

​	原因: springboot 2.0之后默认使用lettuce作为操作redis的客户端;使用netty进行网络通信**;(netty在底层自动计数内存使用量,容量超过了默认限制则会抛出此异常)**

​				lettuce的bug导致的堆外内存溢出,netty如果没有指定堆外内存默认会使用-Xmx指定的内存作为堆外内存

​				设置的无限大的内存也会出现此异常,只是时间延后;因为高并发大量访问,缓存占用的内存无法及时释放积累导致的堆外内存溢出;

​				可以通过命令设置 netty进行设置指定的内存

​	解决:不能只使用命令进行内存增加设置,

- ​	1. 升级**lettuce**客户端(吞吐量大性能好)
- 2. 切换为**jedis**客户端使用同样可以解决问题(老客户端,很久未更新)
     - 排除redis的stater中lettuce依赖
     - 引入jedis依赖,springboot也会默认版本控制;

## 缓存失效

### 缓存击穿

- ​	对于一些设置了过期的key,如果这些key可能在某个时间点被高并发的访问,是一种非常热点的数据;
- ​    如果此时这个key正好失效,那么所有对于这个key的请求会打到数据库上查询;

#### 解决

​	**加锁; 大量的并发只让一个人去查,其他人等待,查到以后释放锁;其他人查询时就会先查询缓存,缓存有数据就不会去数据库;**

### 缓存穿透

- ​	查询一个一定不存在的数据,由于缓存是未命中的将会去查数据库;数据库中也没有,便不会写入缓存;导致每次此请求都会去访问数据库

  #### 风险

  ​	利用不存在的数据进行攻击,导致数据库压力增大,导致崩溃

  #### 解决

  ​	**将null空结果 进行缓存,并加入短暂的过期时间;几分钟**

### 缓存雪崩

-    缓存中大量的key,采用了相同的过期时间,导致某一时刻同时失效,大面积失效,导致大量的访问打到了数据库上;数据库压力过大导致崩溃

#### 解决

​	**在原有的失效时间上增加一个1-5分钟左右的随机值,将大面积失效时间错开;这样大面积缓存失效的几率就会降低;**

# 分布式锁

## 实现及原理

#### 本地锁

​	本地锁只能锁住当前进程,但是性能相对较高

​	本地所只针对当前this, 多个服务时便会有多个this,会导致每个服务都会有进程查询到数据库;

#### 分布式锁

​	分布式锁可以锁住分布式环境下的进程,但是性能较低

##### 原理

​	所有的服务都去一个**公共的地方占锁**,占到了之后即为拥有锁,其他服务没有锁开始等待,;比如去redis占锁

​	**等待可以使用自旋的方式**

#### 实现

​	通过redis实现,多个服务同时往redis中set一个key  成功set的后即为获得锁

​	使用redis`set key value NX`命令实现, key 与 value自定义 NX是必须携带的参数, 意思为只有在redis中当前没有存在这个key时才能set成功,set成功返回ok;     NX=>Not Exists,但是此方法有死锁的风险;

​	**使用redis`set key value EX 秒数 NX`  原子操作,在setkey时便设置锁的过期时间,可以避免死锁;** 

​	RedisTemplate中对应方法`setIfAbsent()` 返回值为Boolean类型 set结果

​	获取锁的进程执行完业务后释放锁,执行delete()方法删除key, 其他被阻塞进程执行自旋与重试机制;

- **加锁使用原子操作**
- **删锁使用redis脚本**

##### **死锁**

​	当程序在执行业务逻辑时,出现异常,不能执行删除锁逻辑会导致死锁;

​	**解决1: 需要给key上一个过期时间,自动过期; **但是在设置过期时间之前就出现异常,仍会出现死锁

​	**解决2:在set key 获取锁的时候,通过原子操作,set时便设置过期时间;**

##### 业务超时删除锁

​	当前服务超时,执行删除锁操作时,redis中的key如果已经过期,则已经有另外一个进程进入且设置了key,再执行删除key时删除的是其他进程key,便会导致另外一个进程再进入业务逻辑;

​	解决 : 在设置key的value时指定一个uuid,再删除前get()获取key的value对比uuid与创建时是否相同, 一样则删除,不同则不删; **//不推荐**

##### 删除锁的原子性

​	在get(key) 获取uuid后,本地对比的过程中,如果key刚好过期,其他进程就会setkey进入,此时执行删除锁仍然后删除别的进程的锁;

​	解决: 删除锁必须保证删除的原子性,需要通过redis设置脚本来实现; 

`String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"`

`redisTemplate.excute(new DefaultScript<Integer>(script脚本字符串 ,返回值类型.classs),Arrays.asList("lock"),uuid)`

- `DefaultScript 类三个构造参数`
- ``第一个是执行的脚本`
- `第二个是返回值类型class`
- `第三个是脚本中的变量,key,第四个是变量value `

```java
try{
    String uuid = xxx;
    Boolean flag = redisTeplate().opsForValue().setIfAbsent("lock",uuid,时间,时间单位TimeUnit.常量); // 1. setKey推荐 或所且设置过期时间
    if(flag){
        // 2 ....调用业务逻辑获取返回值
        ....
        
        rerurn 业务逻辑结果;
    }else{
        // 重试频繁 执行线程休眠 
        Thread.sleep(100)
        return this.此方法;      //4. 重复调用自身 自旋逻辑
    }
}catch(Exception e){
	...
}finally{
    // 3 . 删除所
    String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
    redisTemplate.excute(new DefaultScript<结果类型>(script脚本字符串 ,结果Class),Arrays.asList("lock"),uuid);
}
```

#### 锁的自动续期

​	业务的执行时间超长,锁可能过期;

- 简单处理方式 : 锁设置超长过期时间, try业务逻辑, 无论发生什么错误都进行锁的删除 即可不用实现锁的续期;

#### 锁的时序

​	保证锁的原子性. 进入锁 确认缓存信息, 查询数据库,放入缓存 必须在锁內完成否则可能产生多次查询数据库的问题

## Redisson分布式锁

​	redis官方提供实现的分布式锁,依赖有redisson与redisson-spring-boot-starter;

#### redisson的配置与使用

​	**配置注入RedissonClient对象**

​	参考官方文档 https://github.com/redisson/redisson/wiki/2.-%E9%85%8D%E7%BD%AE%E6%96%B9%E6%B3%95

##### 配置类方式

```java
// 默认连接地址 127.0.0.1:6379
RedissonClient redisson = Redisson.create();

Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:6379");  //addr 必须以redis或rediss(开启了安全连接)开头
RedissonClient redisson = Redisson.create(config);
return redisson;  //注入到ioc容器,之后可以使用此客户端你
```

##### 配置文件方式

 参考github;

## Redisson可重入锁与同步器

​	redisson也实现了juc接口,使用方式与其他juc基本相同;

#### 使用方式

```java
// 1. 注入RedissonClient客户端
	RedissonClient redisson;
// 2. 调用方法获取锁,传入一个名字
	RLock lock = redisson.getLock("自定义锁名");    //多个服务便会调用同一个锁
// 3. 执行加锁.lock(), try无论是否出现异常都要执行解锁, 加锁成功会继续执行,否则阻塞
    lock.lock();     //阻塞式等待,拿不到锁就会再此一直等待 尝试
try{
	...业务逻辑
}catch(...){
		...
}finally{
// 4.释放锁
	lock.unlock(); 
}
```

##### 原理

​	redis底层通过传入的锁名作为key存入redis, 生成唯一id为value; 

​	redisson即是出现服务器断电无法释放锁,也不会出现死锁;

​	redisson中有个看门狗机制,锁会有自动续期; 业务时间长锁会自动续期,默认时间都是30s;

##### 问题

​	也支持自定义锁过期时间,但是看门狗机制边会失效;

​	**指定超时时间后redisson会使用我们的超时时间执行脚本命令,不会自动续期;**

​	`lock.lock(时间,时间单位);`

​	**如果未指定超时时间会使用看门狗机制默认时间30s; 占锁成功会启动一个定时任务在1/3看门狗时间10s后,定时给锁续期;**

##### 最佳使用

​	推荐使用`lock.lock(时间,TimeUnit.时间单位);` 指定过期时间,可以给大一些过期时间,省去自动续期; 超长业务一般是出现了问题;

## Redisson读写锁

​	在两个业务逻辑中,一个业务需要更新数据, 一个业务需要读取数据, 保证读业务读取到的一直是最新的数据;

​	**当写锁存在时,读锁就会生效,直到写锁释放; 如果不存在 写锁,读锁也不会生效;**

​	通过 `getReadWriteLock(自定义锁名)` 方法获取**RReadWriteLock**锁,调用方法`writeLock()`获上写锁,`readLock()`上读锁;

- 写锁是一个互斥锁,排他锁
- 读锁是一个共享锁,多个线程都能使用;

#### 使用

```java
// 1. 注入RedissonClient
// 写逻辑
void xx(){
	//2. 获取写锁,执行加锁
	RReadWriteLock lock = = redisson.getReadWriteLock("自定义锁名");  //读写锁需要获取同名
	lock.writeLock();    //加锁成功  读锁进入阻塞
	...业务是逻辑
	
	//3. 释放锁, 最好finally中
	lock.unlock();      
}

//读逻辑
void xx(){
	//2. 获取写锁,执行加锁
	RReadWriteLock lock = = redisson.getReadWriteLock("自定义锁名");  //读写锁需要获取同名
	lock.readLock();    //加锁成功  读锁进入阻塞
	...业务是逻辑
	
	//3. 释放锁, 最好finally中
	lock.unlock();      
}
```

#### 读写锁补充

- 写 + 读 :等待写锁释放
- 写 + 写 :阻塞方式
- 读 + 写 : 读完成后,写才会加锁成功
- 读 + 读 : 相当于无锁,但是在redis中会记录锁,都会加锁成功

**只要有写锁存在,就会进入等待;**

## Redisson闭锁

通俗理解就是放假锁门,所有班级走完才可以锁门;

通过`getCountDownLatch("自定义锁名")`获取**RCountDownLatch**锁,

 `trySetCount(数值)` 设置计数器,闭锁的条件; 

`await()`等待执行闭锁

另一个逻辑中调用`countDown()`  相当于计数器-1,当计数器为0 ; 等待的闭锁的逻辑便会执行闭锁;

```java
// 1. 注入RedissonClient
//闭锁逻辑
void xx{
	RCountDownLatch lock = redisson.getCountDownLatch("锁名");
	lock.trySetCount(5);   //五次后执行闭锁
	lock.await();          //等待执行闭锁
}

//闭锁等待的逻辑
void xx{
	RCountDownLatch lock = redisson.getCountDownLatch("锁名");
	lock.countDown();     //执行一次相当于计数器-1,无论多少个服务,闭锁的次数是共用的;
}
```

## Redisson信号量

​	通俗理解,去停车,受限制于停车位的数量;获取信号即为占一个车位,释放信号为释放一个车位;

​	**先在redis中存储 key为信号名,值为信号量的键值对**,**可以进行分布式的限流操作;**

​	通过`getSemaphore("redis中信号名")`获取**RSemaphore**对象; 

​	`acquire()`获取一个信号; **阻塞方法,没有信号则必须等待;**

​	`tryAcquire` 尝试获取一个信号,获取失败不阻塞,返回false

​	`release()`释放一个信号;

```java
1 . redis中存储 key value  -> 例: park : 10  即为初始值10,获取一个-1,释放一个+1;最多10最少0;
// 2. 注入RedissonClient
//获取信号逻辑
void xx{
	//3 .获取信号
	RSemaphore lock = redisson.getSemaphore("信号名");
	lock.acquire();   //获取一个信号位
}

//释放信号逻辑
void xx{
	//4 .释放信号
	RSemaphore lock = redisson.getSemaphore("信号名");
	lock.release();   //释放一个信号为
}

```

## 缓存一致性

​	缓存中的数据如何和数据库中保存一直,两种常用解决方案,但是在大并发下都会有一些问题

##### 双写模式

​	**更新数据库后再执行更改缓存数据的操作;**

**问题:**

​	更新缓存时中间有时间空挡,可能被其他线程更新;产生脏数据的风险;

 **解决:** 

​			1 . **加锁,保持操作的一致性**

​			2.**数据允许有暂时的不准确的情况存在;但是要给缓存增加过期时间;**

##### 失效模式

​	**更新数据库后直接删除缓存中的数据; 下次查询方法就会查询一次数据库主动更新;**

**问题:** 

​	写与读的并发问题,可能导致更新的数据被另一个进程覆盖为旧数据产生脏数据; 常更新的数据考虑是否要加入到缓存中

​	<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210122201634.png" alt="image-20210116172850537" style="zoom:33%;" />

**解决:**

​	常更新的数据可以不放入缓存中;缓存增加过期时间,即是产生脏数据也是暂时性的问题;

### 解决方案

- **用户维度的数据往往不会有大并发的情况,所以用户维度的数据可以放入缓存中每隔一段时间触发自动更新即可;**
- **菜单,介绍等基础数据,数据一致性可以通过阿里巴巴中间件Canal订阅同步服务同步数据库的更新**
- **缓存数据+过期时间同样可以解决大部分业务对于缓存的使用要求**
- **通过加锁保证并发的读写, 加读写锁,并发写的时候,写操作排队执行,读操作可以并发执行;**(业务不关心脏数据允许临时在脏数据可以忽略)

**总结**

​	能放入**缓存的数据就是实时性 ,一致性要求不高的**;加上**缓存过期时间保证触发下次主动更新**每天定时更新即可;

​	**读写数据的时候增加上分布式读写锁;**

​	不应该过度设计增加系统的复杂性;

## SpringBoot整合Cache

- Cache接口
  - 定义了缓存的组件规范,包含缓存的各种操作集合,提供了各种cache的实现:RedisCache EhCacheCache等

- CacheManager接口
  - 缓存管理器,用来管理各种缓存

#### 使用

​	1 . springboot自动配置,

​	2 . 配置reids, 指定缓存类型为redis, spring.cache.type=redis

​	3 . 使用注解

- `@Cacheable ` 将返回值保存到缓存   值可以指定key,value分区,条件等 

- `@CacheEvict   ` 删除缓存

- ` @CachePut `  修改缓存

- ` @Caching `    缓存多条件组合配置

- ` @CacheConfig `  缓存公共配置 类级别

- `@EnableCache`   开启缓存

  

#### 默认

​	缓存默认序列化是jdk的序列化机制

​	key自动生成是指定的value值+自动生成的key

#### 自定义

- 自定义缓存使用的key         **接收一个SpEL表达式**,普通字符串一定要加上单引号
- 自定义缓存的序列化机制    **配置文件中指定`spring.cache.redis.time-to-live=毫秒`** 
- 自定义缓存的存活时间       **自定义CacheManager**
  - 缓存的CacheAutoConfigration自动导入了RedisCacheConfigration,拿到其配置进行应用
  - 如果RedisCacheConfigration中有配置则使用,没有则默认
  - 想更改redis设置则只需要给当前容器中放入一个RedisCacheConfigration类进行配置即可
- `spring.cache.redis.key-prefix=key前缀 ` 自定义指定key前缀
- `spring.cache.redis.use-key-prefix=true` 开启使用key前缀
- `spring.cache.redis.cache-null-values=true` 缓存一个空值防止缓存穿透

### Spring Cache不足 

- 读模式
  - 缓存穿透   -> 缓存空数据
  - 缓存击穿   -> 加锁 -> 默认没有加锁 ->**Cacheablez中属性sync=true可以开启本地锁**仅针对读模式
  - 缓存雪崩   -> 添加随机过期时间
- 写模式(缓存与数据库的一致性)
  - 读写加锁
  - 引入中间件Canal感知更新
  - 读多写多直接访问数据库
- **常规数据(读多写少,及时性,一致性要求不高的)可以使用springcache**
- **特殊数据,又需要放入缓存的,则需要针对设计缓存**

# 异步多线程

## 多线程

- 继承 **Thread**类  重写run方法
- 实现 **Runnable** 接口, 重写run方法，
  -  new一个Thread传入Runnable的实现类对象
- 实现 **Callable**<V> 接口,重写call方法, 
  - new **FutureTask**对象,传入Callable实现类, 
  - new一个Thread传入FutureTask对象
  - 通过FutureTask对象获取返回值 **get**()

#### Thread

​	开启一个新线程的类, start()方法开始执行方法体; 

​	构造方法支持传入 线程名 name, Runnable实现独享 target, 线程分组 ThreadGroup ... 等信息 最大6个参数

​	构造方法的本质最终都是调用器init初始化方法进行初始化;

#### **Runnable** 

​	Thread类实现了此接口; FutureTask实现RunnableFuture 实现Runnable接口;

## 线程池

​	alibaba代码检查规范推荐使用**ThreadPoolExecutor**创建线程池,而不是使用其子类   ,因为这种方式可以指定更多的参数更好的定制线程池;

![image-20210120172231916](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210122201817.png)

## ThreadPoolExecutor线程池

### 七大参数

- `int corePoolSize`,        核心线程数, 常驻线程池中的数量, 除非
- `int maximumPoolSize`,  最大线程数,控制资源
- `long keepAliveTime, `  存货时间,超过后将释放核心线程数以外的线程
- `TimeUnit unit,  `             时间单位TimeUnit 常量
- `BlockingQueue<Runnable> workQueue,`  阻塞队列, 如果提交了很多任务,超过线程数的人任务会保存进入队列中排队等待线程取出执行, 系统提供了实现类,也可以自己编写;
  - `new LinkedBlockingDeque()` 默认是Integer的最大值, 可以保存21亿的任务会导致占满内存,一定要指定任务数量;
- `ThreadFactory threadFactory,`              线程的创建工厂,讲一个Runable包装成一个Thread对象.通过启动Thread对象来启动线程
  - `Executors.defaultThreadFactory()`;    defaultThreadFactory不可以直接new,通过Executors工厂类实现,同样支持自定义
- `RejectedExecutionHandler handler`     拒绝处理器, 如果当前队列满了,其他任务就会执行指定的拒绝策略,拒绝执行任务
  - 默认的拒绝处理器是 **丢弃策略**;  `new ThreadPoolExecutor.AbortPolicy()`;
  - `CallerRunsPolicy`  不以异步执行额策略,直接调用run方法执行;  不抛弃进行执行的策略

### 执行顺序

1. 线程池创建, 准备好core线程数,准备接受任务
2. 接收任务执行
   1. core满了就会放到workQueue阻塞队列中等待
   2. 阻塞队列满了,直接开新线程,最大新开线程数是maximumPoolSize的数量
   3. maximumPoolSize满了就会执行handler拒绝策略
   4. 如果maximumPoolSize没有满,在执行完任务后的keepAliveTime后被释放
3. 如果core与workQueue和maximumPoolSize都满了将会执行拒绝策略; handler

### Executors的线程池类型

- `Executors.newCacheThreadPool` 带缓存的线程池
- `Executors.newFiexdThreadPool` 固定线程数, core=max
- `Executors.newScheduledThreadPool` 指定定时任务的线程池
- `Executors.newSingleThreadPool` 单线程的线程池,核心与最大 = 1 ,从队列里获取任务挨个执行

## CompletableFuture异步编排

​	jdk1.8之后添加的功能; 提供了四个静态方法创建一个异步操作;



### 创建异步对象

------

​	通过**CompletableFuture**调用静态方法创建;

​	**Future对象的get方法是个阻塞方法,会等待线程执行完毕执行**

#### runAsync

- `static CompletableFuture<void> runAsync(Runable runable)`    无返回值,默认线程池
- `static CompletableFuture<void> runAsync(Runable runable,Executor executor) ` 无返回值指定线程池

#### supplyAsync

- `static CompletableFuture<U> supplyAsync(Supplier<U> supplier) `   有返回值,默认线程池;没有入参只有出参

- `static CompletableFuture<U> supplyAsync(Supplier<U> supplier,Executor executor) `   有返回值,指定线程池; 没有入参只有出参

  <!--返回值是Future对象, 通过get()方法可以获取返回值, 且可以通过Future对象实现链式调用;-->

  

### 计算完成时回调方法

------

#### whenComplete

​	链式调用,直接通过异步对象Future调用方法即可

- `CompletableFuture<T> whenComplete(BiConsumer<? super T,? super Throwable> action)`

  <!--能够得到异常信息,但是不能修改返回值-->

- `CompletableFuture<T> whenCompleteAsync(BiConsumer<? super T,? super Throwable> action)`

- `CompletableFuture<T> whenCompleteAsync(BiConsumer<? super T,? super Throwable> action,Executor executor)`

#### exceptionally

- `CompletableFuture<T> exceptionally(Function<Throwable ,? extends T> fn)`

  <!--能够感知异常,同时返回默认值修改返回值;-->

  **参数**

  -  BiConsumer<? super T,? super Throwable> action  第一个是结果,第二个是异常;  使用lambda 传入两个形参即可,**形参是上一个方法传递下来的 结果,异常;**

带Async的方法是以异步的方式执行回调方法; 不带Async的是使用当前线程继续执行



### handle方法

------

​	和Complete方法一样,**能够对结果做最后处理; 但是能够处理异常**;

- `public<U> CompletableFuture<U> handle (BiFunction<? super T, Throwable  extends U fn>)`

  <!--第一个参数是结果,前一个方法传递下来的  第二个参数是异常,前一个方法产生的异常-->

- `public<U> CompletableFuture<U> handleAsync (BiFunction<? super T, Throwable  extends U fn>)`

- `public<U> CompletableFuture<U> handleAsyn (BiFunction<? super T, Throwable  extends U fn>,Executor executor)`

  带Async的方法是以异步的方式执行回调方法; 不带Async的是使用当前线程继续执行

  

### 线程串行化方法

------

#### thenApply

- `public <U> CompletableFuture<U> thenApply(Function<? super T, ? extends U> fn)`
- `public <U> CompletableFuture<U> thenApplyAsync(Function<? super T, ? extends U> fn)`
- `public <U> CompletableFuture<U> thenApplyAsync(Function<? super T, ? extends U> fn,Executor executor)`

<!-- thenApply方法：当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前 任务的返回值,返回值的泛型写在返回的CompletableFuture<泛型>中, 不能卸载调用方法的CompletableFuture中-->

#### thenAccept

- `public CompletableFuture<void> thenAccept(Consumer<? super T> action)`
- `public CompletableFuture<void> thenAcceptAsync(Consumer<? super T> action)`
- `public CompletableFuture<void> thenAcceptAsync(Consumer<? super T> action,Executor executor)`

<!-- thenAccept 方法：消费处理结果。接收任务的处理结果，并消费处理，无返回结果。-->

#### thenRun

- `public CompletableFuture<void> thenRun(Runable action)`
- `public CompletableFuture<void> thenRunAsync(Runable action)`
- `public CompletableFuture<void> thenRunAsync(Runable action,Executor executor)`

<!-- thenRun 方法：只要上面的任务执行完成，就开始执行 thenRun，只是处理完任务后执行不接收返回值也无返回值 -->



### 两任务组合 All

------

​	Completionstage是CompletableFuture的父接口

#### thenCombine 

- `public <U,V> CompletableFuture<V> thenCombine (Completionstage<? extends U> other,BiFunction <? super T, ? super V ,? extends V> fn)`
- `public <U,V> CompletableFuture<V> thenCombineAsync (Completionstage<? extends U> other,BiFunction <? super T, ? super V ,? extends V> fn)`
- `public <U,V> CompletableFuture<V> thenCombineAsync (Completionstage<? extends U> other,BiFunction <? super T, ? super V ,? extends V> fn , Executor executor)`

<!--thenCombine 组合两个 future，获取两个 future 的返回结果，并返回当前任务的返回值,T是当前任务返回值,U是加入任务的返回值,V是方法的返回值 -->

#### thenAcceptBoth

- `public <U> CompeletableFuture<void> thenAcceptBoth(ComplationStage<? extends U> other, BiConsumer<? super T, ? super U> action)`
- `public <U> CompeletableFuture<void> thenAcceptBothAsync(ComplationStage<? extends U> other, BiConsumer<? super T, ? super U> action)`
- `public <U> CompeletableFuture<void> thenAcceptBothAsyn(ComplationStage<? extends U> other, BiConsumer<? super T, ? super U> action,Executor executor)`

<!--组合两个 future，获取两个 future 任务的返回结果，然后处理任务，没有 返回值 -->

#### thenAfterBoth

- `public CompletableFuture<void> thenAfterBoth(ComplationStage<?> other)`
- `public CompletableFuture<void> thenAfterBothAsync(ComplationStage<?> other)`
- `public CompletableFuture<void> thenAfterBothAsync(ComplationStage<?> other,Executor executor)`

<!--runAfterBoth：组合两个 future，不需要获取 future 的结果，只需两个 future 处理完任务后， 处理该任务-->



### 两任务组合 Any

------

#### applyToEither

- `public <U> CompletableFuture<U> applyToEither(CompletionStage<? extends T> other ,Function<? super T,U> fn)`
- `public <U> CompletableFuture<U> applyToEitherAsync(CompletionStage<? extends T> other ,Function<? super T,U> fn)`
- `public <U> CompletableFuture<U> applyToEitherAsync(CompletionStage<? extends T> other ,Function<? super T,U> fn,Executor executor)`

<!--applyToEither：两个任务有一个执行完成，获取它的返回值，处理任务并有新的返回值。-->

#### acceptEither

- `public CoMpletableFuture<void> acceptEither(CompletionStage<? extends T> other ,Function<? super T> fn)`
- `public CompletableFuture<void> acceptEitherAsync(CompletionStage<? extends T> other ,Function<? super T> fn)`
- `public CompletableFuture<void> acceptEitherAsync(CompletionStage<? extends T> other ,Function<? super T> fn,Executor executor)`

<!--acceptEither：两个任务有一个执行完成，获取它的返回值，处理任务，没有新的返回值。-->

#### runAfterEither

- `public CompletableFuture<void> runAfterEither(CompletionStage<? extends T> other ,Runable action)`
- `public CompletableFuture<void> runAfterEitherAsync(CompletionStage<? extends T> other ,Runable action)`
- `public CompletableFuture<void> runAfterEitherAsyn(CompletionStage<? extends T> other ,Runable action,Executor executor)`

<!--runAfterEither：两个任务有一个执行完成，不需要获取 future 的结果，处理任务，也没有返 回值。-->



### 多任务组合

------

- `public static CompletableFuture<void> allOf(CompletableFuture<?>...cfs)`
- `public static CompletableFuture<Object> anyOf(CompletableFuture<?>...cfs)`

<!-- allOf：等待所有任务完成    anyOf：只要有一个任务完成  调用get()方法进入阻塞-->

# Spring Session分布式Session共享

## 核心原理

1. ### @**EnableRedisHttpSession** 注解

   - Import 导入了RedisHttpSessionConfigration
     - @Bean 给容器添加了一个**RedisOperationSessionRepository**组件,redis操作session增删改查的封装类
     - 放入了一个**SessionRepositoryFilter** 存储Session的过滤器; --> 就是Http的Filter过滤器
       - 创建的时候自动从容器中获取到了SessionRepository

2. ### 核心原理**SessionRepositoryFilter**   装饰者模式

   1. **doFilterlternal**()方法中将原生的Request Response Context包装, 放行的是包装后的对象,放行到了后面的执行链
   2. 到了Controller中,获取原生HttpRequest中的Session获取时,此对象已经被包装;
   3. 以后再获取Session时都需要调用getSession()
   4. 每次调用都是调用包装类的getSession() ,重写了实现逻辑
   5. 本质是通过**装饰者模式**, 调换获取到的 getSession()方法

   每次需要变更存储的位置Redis Map Magodb等 只需要变更放入容器中的Bean;

   Session的自动延期等功能都实现了,Redis中的数据也有过期时间

## 使用

1. 导入<artifactId>spring-session-data-redis</artifactId> springboot默认版本控制

   1. 导入redis -> 配置redis

   2. ```yaml
      spring.session.store-type=redis   #开启session为redis类型  其他类型可了解使用
      ```

2. SessionConfig配置 

   1. 自定义CookieSerializer的Bean   定义session存储在本地cookie的属性信息

      ```java
      @Bean
      public CookieSerializer cookieSerializer(){
         DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer();  //new cookie的新配置
         cookieSerializer.setDomainName("47.116.32.112");	//cookie的作用域
         cookieSerializer.setCookieName("MALLSESSION");  //cookie存储的session名
         return cookieSerializer;
      }
      ```

   2. 自定义RedisSerializer<Object> 定义Redis序列化session的规则

      ```java
      @Bean
      public RedisSerializer<Object> springSessionDefaultRedisSerializer() {
         return new GenericJackson2JsonRedisSerializer();
         //redis序列化session的工具, 此处使用jackson, 可以切换其他实现类
      }
      ```

3. ```   java
   @EnableRedisHttpSession  //开启spring session redis的使用注解  生命在启动类或配置类
   ```

4. Spring通过Filter使用装饰者模式修改HttpServletRequest.getSession()获取到的session, 所以正常使用即可,与原生API相同;

[Spring Session 官方文档](https://docs.spring.io/spring-session/docs/2.2.5.RELEASE/reference/html5/guides/boot-redis.html)

# 微信支付

## 支付流程

- 根据订单id获取订单信息

- 通过map设置访问微信接口参数

  ```java
   //1、设置支付参数
  m.put("appid", "wx74862e0dfcf69954");
  m.put("mch_id", "1558950191");
  m.put("nonce_str", WXPayUtil.generateNonceStr());
  m.put("body", order.getCourseTitle());
  m.put("out_trade_no", orderNo);
  m.put("total_fee", order.getTotalFee().multiply(new BigDecimal("100")).longValue()+"");
  m.put("spbill_create_ip", "127.0.0.1");
  m.put("notify_url", "http://guli.shop/api/order/weixinPay/weixinNotify\n");
  m.put("trade_type", "NATIVE");
  ```

- HTTPClient来根据URL访问微信支付开放接口并且传递参数

  ```java
  HttpClient client = new HttpClient("https://api.mch.weixin.qq.com/pay/unifiedorder");
  ```

- 设置client的参数信息

  ```java
  //client设置参数
   client.setXmlParam(WXPayUtil.generateSignedXml(m, "T6m9iK73b0kn9g5v426MKfHQH7X8rKwb"));
   client.setHttps(true);
   client.post();
  ```

- 接收返回数据, 微信支付返回值是xml格式, 通过微信支付的工具类转换为map

  ```java
   String xml = client.getContent();
   Map<String, String> resultMap = WXPayUtil.xmlToMap(xml);
  ```

- 封装结果集

- 微信支付二维码2小时过期，可采取2小时未支付取消订单

## 获取支付状态

- 请求微信指定接口,携带对应参数
- 判断返回值的trade_state 是否为 SUCCESS  ,是则为支付成功

```java
@GetMapping("/queryPayStatus/{orderNo}")
public R queryPayStatus(@PathVariable String orderNo) {
    //调用查询接口
    Map<String, String> map = payService.queryPayStatus(orderNo);
    if (map == null) {//出错
        return R.error().message("支付出错");
    }
    if (map.get("trade_state").equals("SUCCESS")) {//如果成功
        //更改订单状态
        payService.updateOrderStatus(map);
        return R.ok().message("支付成功");
    }

    return R.ok().code(25000).message("支付中");
} 

public Map queryPayStatus(String orderNo) {
        try {
            //1、封装参数
            Map m = new HashMap<>();
            m.put("appid", "wx74862e0dfcf69954");
            m.put("mch_id", "1558950191");
            m.put("out_trade_no", orderNo);
            m.put("nonce_str", WXPayUtil.generateNonceStr());

            //2、设置请求
            HttpClient client = new HttpClient("https://api.mch.weixin.qq.com/pay/orderquery");
            client.setXmlParam(WXPayUtil.generateSignedXml(m, "T6m9iK73b0kn9g5v426MKfHQH7X8rKwb"));
            client.setHttps(true);
            client.post();
            //3、返回第三方的数据
            String xml = client.getContent();
            Map<String, String> resultMap = WXPayUtil.xmlToMap(xml);
            //6、转成Map
            //7、返回
            return resultMap;
        } catch (Exception e) {
            e.printStackTrace();
        }
        return null;
    }
```



# 社交登陆

## 微博登录

​	[微博登录API接口](https://open.weibo.com/wiki/API%E6%96%87%E6%A1%A3_V2) [OAuth2 授权API](https://open.weibo.com/wiki/%E6%8E%88%E6%9D%83%E6%9C%BA%E5%88%B6%E8%AF%B4%E6%98%8E)

### 流程

​	<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210123114417.png" alt="image-20210123114410466" style="zoom: 50%;" />

1. 引导用户前往微博指定uri, uri中需要指定appkey 与 回调uri
2. 用户授权成功-> 微博回调指定uri, 携带code参数 (一次性)
3. 获取code参数,通过Http的client 发送请求 ,请求微博token的uri,获取用户uid与token信息; 注解接收返回值
4. 返回值为HttpEntity类型可以通过EntityUtils->字符串->JSON解析为对象; 获取token与uid 请求微博开放的uri获取我们需要的信息
5. 新用户? 注册返回 : 查询返回;

## 微信登陆

微信登录流程与微博基本相同

1. 访问微信开放接口, uri携带商户信息;指定callback地址
2. 编写callback接口,微信授权成功回调此接口; 返回唯一code
3. 通过code访问微信开放获取token的接口,获取用户唯一标识token与uid
4. 通过token与uid访问微信获取用户信息接口,获取返回值 response 包含用户信息;

## 社交登录技术点

- HttpCilent 或者 RestTemplate HttpUtils 等可以发送http请求的api直接访问微信接口获取返回值; 
- JSON转换与格式化获取返回值的信息;



# SSO单点登录

​	基于token的单点登录,weibo社交登录就是单点登录的一个示例;

单点登录的常见实现方式

- **Session** 复制    
  - 极大浪费内存,小型分布式项目可以考虑
- **Cookie** + **Redis**   用户信息存储到redis
  - **用户登录信息存储到Redis ; Cookie中保存唯一的key,每次请求携带Cookie根据key到Redis查询数据**
- Spring Session  Session存储到redis
  - Spring-Session整合了实现, 可以**将Session写入到Redis中.多个分布式服务都从redis中读取,存入session;**
  - 用户请求时,携带唯一的sessionID, 服务器到redis中获取指定key(自定义的key)的session,获取到则是登录成功;
- **toekn** 实现 
  - token是什么?   **按照一定规则生成的包含用户信息的字符串**
  - 在某个模块登录成功后会返回唯一的token包含用户信息,下次请求其他模块会携带token信息; 
  - token返回可以使用uri返回或者cookie返回;  前后分离系统可以通过@ResponseBody直接响应token,前台编写逻辑将token信息放入cookie,然后编写request拦截器将cookie信息放入heards ; 每次请求都会自动携带token; 并且**cookie不支持跨域需要注意;**
  - 访问其他模块时,模块根据token信息获取用户,能够获取到就是已登录; token信息可能在cookie,uri,request中;具体获取方法需要根据业务情况而定;
  - 前后分离实现token登录;<img src="C:/Users/jianjian/AppData/Roaming/Typora/typora-user-images/image-20210125111611946.png" alt="image-20210125111611946" style="zoom: 33%;" />

## JWT令牌  JSON Web Token

授权服务器所颁发的令牌,包含用户或者客户端的元数据与声明;

### 组成

- 是一串很长的加密字符串,通过.进行分割; 每一个子串表示了一个功能块，总共有以下三个部分**：JWT头、有效载荷和签名**

  - **JWT头**  是一个描述 **JWT元数据的JSON对象**

    ```json
    {
      "alg": "HS256",
      "typ": "JWT"
    }
    ```

  - **有效载荷** ，是JWT的主体内容部分，也是一个JSON对象，**包含需要传递的数据**。 **JWT指定七个默认字段供选择**。

    - **默认情况下JWT是未加密的**，任何人都可以解读其内容，因此不要构建隐私信息字段，存放保密信息，以防止信息泄露。

      JSON对象也使用Base64 URL算法转换为字符串保存。

    ```
    iss：发行人
    exp：到期时间
    sub：主题
    aud：用户
    nbf：在此之前不可用
    iat：发布时间
    jti：JWT ID用于标识该JWT
    //除以上默认字段外，我们还可以自定义私有字段，如下例：
    {
      "sub": "1234567890",
      "name": "Helen",
      "admin": true
    }
    ```

  - **签名哈希**   **签名哈希部分是对上面两部分数据签名，通过指定的算法生成哈希，以确保数据不会被篡改**。

    - 首先，需要指定一个**密码（secret**）。该密码仅仅为保存在服务器中，并且不能向用户公开。然后，使用标头中指定的签名算法（默认情况下为HMAC SHA256）根据以下公式生成签名。

    ```
    HMACSHA256(base64UrlEncode(header) + "." + base64UrlEncode(claims), secre
    ```

  - **Base64URL算法 **   

    - 由于在**URL中有特殊含义**，因此Base64URL中对他们做了替换：**"="去掉，"+"用"-"替换，"/"用"_"替换，这就是Base64URL算法。**

### 用法

- 客户端接收服务器返回的JWT，将其存储在Cookie或localStorage中。
- 此后，客户端将在与服务器交互中都会带JWT。**如果将它存储在Cookie中，就可以自动发送，但是不会跨域，因此一般是将它放入HTTP请求的Header Authorization字段中。当跨域时，也可以将JWT被放置于POST请求的数据主体中。**

### 使用

- 整合JWT工具包,  

```
    <dependency>
        <groupId>io.jsonwebtoken</groupId>
        <artifactId>jjwt</artifactId>
    </dependency>
```

- 创建JWT工具类

  ```
  //参考 开发配置文件笔记
  通过JWT工具类进行 token信息的生成,  解密获取指定信息 id name 等
  ```

  

## OAuth2 

- 是一种特定问题的解决方案
  - 开放系统间的授权
    - 微博 微信的社交登录
  - 分布式系统的登录访问问题
    - 分布式系统的单点登录实现
- OAuth2的解决方案 : 令牌机制,按照一定规则生成包含用户信息的字符串



​	

# 消息队列  Message Queue

## 概念

- 消息代理（message broker）
  - 队列（**queue**）：点对点消息通信（point-to-point） 
  - 主题（**topic**）：发布（**publish**）/订阅（**subscribe**）消息通信

- 目的地（destination）
  - 当**消息发送者发送消息以后，将由消息代理接管，消息代理保证消息传递到指定目的地**
- 点对点式
  - 消息发送者发送消息，消息代理将其放入一个队列中，消息接收者从队列中获 取消息内容，消息读取后被移出队列;
  - **消息只有唯一的发送者和接受者，但并不是说只能有一个接收者发布订阅式：**
- 发布订阅式
  -  发送者（发布者）**发送消息到主题，多个接收者（订阅者）监听（订阅）这个主题，那么就会在消息到达时同时收到消息**

### JMS消息服务

```
java规范的消息队列规范, ActiveMQ、HornetMQ是JMS实现
```

### AMQP高级消息队列协议

	高级消息队列协议，也是一个消息代理的规范，兼容JMS RabbitMQ是AMQP的实现

## Spring支持 

- **spring-jms**提供了对JMS的支持
- **spring-rabbit**提供了对AMQP的支持
- 需要**ConnectionFactory**的实现来**连接消息代理**
- 提供**JmsTemplate、RabbitTemplate**来发送消息
- **@JmsListener（JMS）、@RabbitListener（AMQP）**注解在方法上监听消息 代理发布的消息
- **@EnableJms、@EnableRabbit**开启支持

## SpringBoot支持

- **JmsAutoConfiguration**
  - 提供了JMS规范api的支持; 自动配置
- **RabbitAutoConfiguration**
  - 提供了RabbitMQ的配置自动注入
  - **自动配置了RabbitTemplate** **和 AmqpAdmin 以及CachingConnectionFactory , RabbitMessageTemplate对象**

## RabbitMQ

### 概念

- **Message** 消息，消息是不具名的，它由消息头和消息体组成。
  - 消息体是不透明的，而消息头则由一系列的可选属性组成， 
  - 这些属性包括**routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可 能需要持久性存储）**等
- **Publisher** 消息的生产者，也是一个向交换器发布消息的客户端应用程序。
- **Exchange** 交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。
  - Exchange有4种类型：**direct(默认)，fanout, topic, 和headers**，不同类型的Exchange转发消息的策略有所区别
- **Queue** 消息队列，用来保存消息直到发送给消费者。**它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直 在队列里面，等待消费者连接到这个队列将其取走。**
- **Binding** 绑定，用于消息队列和交换器之间的关联。**一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交 换器理解成一个由绑定构成的路由表。 Exchange 和Queue的绑定可以是多对多的关系。**
- **Connection** 网络连接，比如一个TCP连接。
- **Channel** 信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内的虚拟连接，AMQP 命令都是通过信道 发出去的，**不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。**因为对于操作系统来说建立和销毁 TCP 都
  是非常昂贵的开销，所以引入了信道的概念，以复用一条 TCP 连接。
- **Consumer** 消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。
- **Virtual Host** 虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加 密环境的独立服务器域。**每个 vhost 本质上就是一个 mini 版的 RabbitMQ 服务器，拥 有自己的队列、交换器、绑定和权限机制**。vhost 是 AMQP 概念的基础，必须在连接时 指定，RabbitMQ 默认的 vhost 是 / 。
- **Broker** 表示消息队列**服务器实体**



## RabbitMQ整合

### 引入AMQP

1. **引入`spring-bbot-starter-amqp`场景启动器 RabbitAutoConfiguration生效 并配置application文件**
   1. 所有的属性开头是 spring.rabbit
      1. host 主机地址ip
      2. port 5672
      3. virturl-host 虚拟主机 默认是/ 
      4. 其他默认值 账号密码等

### 自动配置

1. **自动配置了RabbitTemplate** **和 AmqpAdmin 以及CachingConnectionFactory , RabbitMessageTemplate对象**
   1. AmqpAdmin  高级消息队列的管理对象,可以创建Exchange , Binding , queue 
   2. RabbitTemplate 可以进行收发消息  发送的消息是对象会使用序列化,必须实现Serializable

### 开启使用

1. **`@EnableRabbit`开启RabbitMQ的使用**
2. `@RabbitListener`**可以声明在类与方法上,在类上声明监听某queue**
3. `@RabbitHandler`**声明在方法上 方法作为一个接收不同类型消息的处理器, 组合`@RabbitListener`,在方法的参数位置可以使用重载的方式接收不同类型的消息**
   1. 在发送消息的时候,可能会发送不同类型的消息, T类型或 K类型 等,接收消息使用RabbitHandler声明的方法 接收不同 K / T类型的参数, 方法就会只接收接收对应类型的消息; **通过标注在方法上重载方法可以实现同一个消息队列中不同类型消息的不同处理逻辑**

- 创建交换机队列绑定关系

  ```java
  AmqpAdmin // 会自动注入,调用方法 可以创建Bingding Exchange Queue  
  ```

- 发送消息

  ```java
  RabbitTemplate  //会自动注入  指定 Exchange 与 routing key 可以发送消息
  ```

- 监听消息

  - 参数1 Message -> 返回的消息 包含header body 等信息
  - 参数2 T 发送消息时的类型, spring会自动转换为对应的对象
  - 参数3 Channal 信道,可以获取到当前传输数据的信道
    - 同一个queue可以被多个消费者监听; 但是只有一个消费者会取到消息; 
    - 只有一个消息完全处理完,才会接收下一个消息;

  ```java
  方式1
  @RabbitListener(queues=["队列名1","队列名2"])   //标注在方法上   //必须先开启@EnableRabbit
  public void test(Object message){   //参数接收消息 自动传入
      System.out.print(message);
  }
  方式2
  @RabbitListener(queues=["队列名1","队列名2"])   //标注在方法上   //必须先开启@EnableRabbit
  public void test(Message message){   //参数接收消息 amqp 核心包中的  消息详细
      byte[] msg = message.getMessageProperties.getBody();   //需要进行json解析等操作
      MessageProperties mp = message.getMessageProperties();
      System.out.print(message.getBody()); 
  }
  方式3
  @RabbitListener(queues=["队列名1","队列名2"])   //标注在方法上   //必须先开启@EnableRabbit
  public void test(Message message,SpuInfo info){   // 会自动将message的body 转换为发送消息时的类型; spring会进行自动转换成对象
      System.out.print(info);   //直接打印对象即可,message的信息也可以正常获取
  }
  
  ```


## RabbitMQ消息确认机制-可靠抵达

保证消息不丢失，可靠抵达，可以**使用事务消息，性能下降250倍**，**为此引入确认 机制**

- **publisher confirmCallback 确认模式** 
- **publisher returnCallback 未投递到 queue 退回模式**
- **consumer ack机制**

### 定制消息

```java
//生产端确认 定制rabbitTemplate
1.Broke收到消息就回调
    spring.rabbitmq.publisher-confirms=true
    rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback(){
        ....重写confirm方法逻辑
    })
2.消息成功投递到Queue就回调
    spring.rabbitmq.publisher-returns=true
    spring.rabbitmq.template.mandatory=true # 优先异步回调
	rabbitTemplate.setReturnMessage(new RabbitTemplate.ReturnCallback(){
        重写returnedMessage...方法逻辑
    })
//消费端确认 保证每个消息被正确处理,Broke才会删除消息保证消息不丢失
1.默认是自动确认的,只要接收到,客户端就会自动ack确认,Broke就会删除消息
    如果收到消息,但是没有处理完 服务器宕机; 那么会导致消息丢失
2.手动确认
    即客户端收到一个消息,处理一个消息,处理完一个消息确认一个消息
    spring.rabbitmq.listener.simple.acknowledge-mode=manual # 手动确认消息  注意是simple的这个配置
    在接收消息的方法中, 通过参数Channel信道可以进行手动确认
    手动确认模式下,只要没有执行手动确认的代码,即是consumer宕机,消息也不会丢失;
        未确认的消息状态为unacked 等待确认
        客户端断开连接未确认 消息状态重置为 ready 准备好
     通过Channel类的方法
            baiscAsck(long deliveryTag, boolean multiple);进行确认
            baiscAsck(long deliveryTag, boolean multiple,boolean requeue); 任务失败拒签,返回队列
            //参数deliveryTag 通过Message.getDeliveryTag()获取此id特点为信道内自增;
            //参数multiple 是否批量确认
            //参数requeue  是否退货,true返回队列,false丢弃
            
```

![image-20210125142132973](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210125142133.png)

### 可靠抵达-ConfirmCallback

- **`spring.rabbitmq.publisher-confirms=true`** 
  -  在创建 connectionFactory 的时候设置 **PublisherConfirms(true)** 选项，开启 confirmcallback 。
  -  CorrelationData：用来表示当前消息唯一性。
  -  消息只要被 broker 接收到就会执行 confirmCallback，如果是 cluster 模式，需要所有 broker 接收到才会调用 confirmCallback。
  -  **被 broker 接收到只能表示 message 已经到达服务器，并不能保证消息一定会被投递**
     **到目标 queue 里。所以需要用到接下来的 returnCallback 。**

#### 使用

- 配置`spring.rabbitmq.publisher-confirms=true`
- 配置rabbitTemplate,添加一个ConfirmCallback对象;
  - ConfirmCallback是RabbitTemplate的内部类

```java
@Autowire
RabbitTemplate rabbitTemplate;
@PostConstruct  //在类构造方法执行完成后执行
public void addConfirmCallback(){
    rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback(){
        
        @Override
        
    })
}
```



### 可靠抵达-ReturnCallback

- **`spring.rabbitmq.publisher-returns=true`**
- **`spring.rabbitmq.template.mandatory=true`**
  - **confrim 模式只能保证消息到达 broker，不能保证消息准确投递到目标 queue 里**。在有 些业务场景下，我们需要保证消息一定要投递到目标 queue 里，此时就需要用到 return 退回模式。
  - **这样如果未能投递到目标 queue 里将调用 returnCallback** ，可以记录下详细到投递数
    据，定期的巡检或者自动纠错都需要这些数据。

### 可靠抵达-Ack消息确认机制

- **消费者获取到消息，成功处理，可以回复Ack给Broker**
  - **basic.ack**用于肯定确认；broker将移除此消息 
  - **basic.nack**用于否定确认；可以指定broker是否丢弃此消息，可以批量
  - **basic.reject**用于否定确认；同上，但不能批量
- **默认自动ack，消息被消费者收到，就会从broker的queue中移除** 
- **queue无消费者，消息依然会被存储，直到消费者消费** 
- **消费者收到消息，默认会自动ack。**但是如果无法确定此消息是否被处理完成，或者成功处理。我们可以开启手动ack模式 
  - 消息处理成功，**ack()**，接受下一个消息，此消息broker就会移除
  - 消息处理失败，**nack()/reject()**，重新发送给其他人进行处理，或者容错处理后ack
  - 消息一直没有调用ack/nack方法，broker认为此消息正在被处理，不会投递给别人，此时客户端断开，消息不会被broker移除，会投递给别人

## RabbitMQ延时队列（实现定时任务）

- 常用解决方案： 
- spring的 **schedule** 定时任务轮询数据库
  -  缺点：
     - 消耗系统内存、增加了数据库的压力、存在较大的时间误差
- 解决：**rabbitmq的消息TTL和死信Exchange结合**;  发送一个定时消息,从而达到实现定时任务的功能;

### 消息的TTL（Time To Live）

- 消息的TTL就是**消息的存活时间。**
- **RabbitMQ可以对  <u>队列和消息</u>  分别设置TTL。**
  - 对队列设置就是队列没有消费者连着的保留时间，**也可以对每一个单独的消息做单独的 设置。超过了这个时间，我们认为这个消息就死了，称之为死信。**
  - **如果队列设置了，消息也设置了，那么会取小的。**所以一个消息如果被路由到不同的队 列中，这个消息死亡的时间有可能不一样（不同的队列设置）。
  - 这里单讲单个消息的 TTL，因为它才是实现延迟任务的关键。**可以通过设置消息的expiration字段或者x-message-ttl属性来设置时间，两者是一样的效果。**

### Dead Letter Exchanges（DLX）

- **一个消息在满足如下条件下，会进死信路由，**记住这里是路由而不是队列， 一个路由可以对应很多队列。
- （什么是死信）
  - 一个消息被Consumer拒收了，并且reject方法的参数里requeue是false。也就是说不 会被再次放在队列里，被其他消费者使用。（basic.reject/ basic.nack）requeue=false
  - 上面的消息的TTL到了，消息过期了。
  - 队列的长度限制满了。排在前面的消息会被丢弃或者扔到死信路由上
- **Dead Letter Exchange其实就是一种普通的exchange，和创建其他 exchange没有两样**。只是在某一个设置Dead Letter Exchange的队列中有 消息过期了，会自动触发消息的转发，发送到Dead Letter Exchange中去。
- 我们既可以**控制消息在一段时间后变成死信，又可以控制变成死信的消息被路由到某一个指定的交换机，结合二者，其实就可以实现一个延时队列**
- 手动ack&异常消息统一放在一个队列处理建议的两种方式
  - catch异常后，手动发送到指定队列，然后使用channel给rabbitmq确认消息已消费
  - 给Queue绑定死信队列，使用nack（requque为false）确认消息消费失败

![image-20210125144853168](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210125144853.png)

### 延时队列实现-1

<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210125144913.png" alt="image-20210125144913648" style="zoom: 50%;" />

### 延时队列实现-2

![image-20210125144953404](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210125144953.png)

### 订单延时实现

![image-20210125145119732](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210125145119.png)

![image-20210125145159736](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210125145159.png)

### SpringBoot中使用延时队列

- 1、**Queue、Exchange、Binding可以@Bean进去**
- 2、**监听消息的方法可以有三种参数（不分数量，顺序）**
  - **Object** content, **Message** message, **Channel** channel
- 3、**channel可以用来拒绝消息，否则自动ack；**

## 如何保证消息可靠性

### 消息丢失

-  消息发送出去，由于网络问题没有抵达服务器 
   - 做好**容错方法（try-catch）**，发送消息可能会网络失败，失败后要有重试机 制，可记录到数据库，采用定期扫描重发的方式
   - 做好**日志记录**，每个消息状态是否都被服务器收到都应该记录 
   - 做好**定期重发**，如果消息没有发送成功，定期去数据库扫描未成功的消息进 行重发
-  消息抵达Broker，Broker要将消息写入磁盘（持久化）才算成功。此时Broker尚 未持久化完成，宕机。
   -  **publisher也必须加入确认回调机制**，确认成功的消息，修改数据库消息状态。
-  自动ACK的状态下。消费者收到消息，但没来得及消息然后宕机
   - 一定开启**手动ACK，消费成功才移除**，失败或者没来得及处理就noAck并重新入队

### 消息重复

-  消息消费成功，事务已经提交，ack时，机器宕机。导致没有ack成功，Broker的消息 重新由unack变为ready，并发送给其他消费者
-  消息消费失败，由于重试机制，自动又将消息发送出去
-  成功消费，ack时宕机，消息由unack变为ready，Broker又重新发送 
   - 消费者的业务**消费接口应该设计为幂等性**的。比如扣库存有 工作单的状态标志
   - 使用**防重表（redis/mysql）**，发送消息每一个都有业务的唯 一标识，处理过就不用处理
   - rabbitMQ的每一个消息都有**redelivered字段**，可以获取是否是被重新投递过来的，而不是第一次投递过来的

### 消息积压

- 消费者宕机积压
- 消费者消费能力不足积压
- 发送者发送流量太大
  - **上线更多的消费者，进行正常消费**
  - **上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理**

# 接口的幂等性

## 概念

- 基本概念
  - **接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因 为多次点击而产生了副作用(多次提交)**
- 哪些情况需要进行幂等性处理
  - 用户多次点击按钮 
  - 用户页面回退再次提交 微服务互相调用，
  - 由于网络问题，导致请求失败。feign 触发重试机制
  - 其他业务情况

## 幂等解决方案

### token 机制 (常用)

1. **服务端提供了发送 token 的接口。**我们在分析业务的时候，哪些业务是存在幂等问题的， 就必须在**执行业务前，先去获取 token，服务器会把 token 保存到 redis 中。**

2. 然后**调用业务接口请求时，把 token 携带过去**，**一般放在请求头部。**

3. 服务器判断 token 是否存在 redis 中，**存在表示第一次请求，然后删除 token,继续执行业务**。

   1. **删除token应当是原子操作(使用redis的脚本 或者 加锁) 使用脚本script性能更好**
   2. **删除token应该在业务执行前删除,业务失败的话再次获取token即可**

4. 如果判断 **token 不存在 redis 中，就表示是重复操作**，直接返回重复标记给 client，这样 就保证了业务代码，不被重复执行

   ```java
   1. 在请求页面是 返回数据携带token字符串存储在当前页面
   2. 服务器将token存储在redis中
   3. 前台页面发起请求,会携带token,接口进行token校验; (在业务执行前, 且必须是原子操作)
   4. if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end
   5. Long execute = redisTemplate.execute(
           new DefaultRedisScript<Long>(script, Long.class), Arrays.asList(vo.getOrderToken() + Loginnterceptor.loginUser.get().getId()), orderToken);
           // 参数DefaultRedisScript<Long> 泛型指定返回值类型,参数1指定脚本script的字符串 参数2返回值类型.class
   		// 参数2 KEYS[1]占位符的参数, List集合,指定token在redis中存储的key
   		// 参数3 ARGV[1]占位符的参数, 进行redis校验的参数,前台携带过来的token;
        
   ```

### 各种锁机制

#### 	1.数据库悲观锁

​	**悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用**。 另外要注意的是，id 字段一定是主键或者唯一索引，不然可能造成锁表的结果，处理起来会非常麻烦。

####  	2.数据库乐观锁

​	**这种方法适合在更新的场景中**

​	update t_goods set count = count -1 , version = version + 1 where good_id=2 and version = 1 根据 version 版本，**也就是在操作库存前先获取当前商品的 version 版本号，然后操作的时候 带上此 version 号。**我们梳理下，我们第一次操作库存时，得到 version 为 1，调用库存服务 version 变成了 2；但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订 单服务传如的 version 还是 1，再执行上面的 sql 语句时，就不会执行；因为 version 已经变 为 2 了，where 条件就不成立。这样就保证了不管调用几次，只会真正的处理一次。**乐观锁主要使用于处理读多写少的问题**

#### 	3.业务层分布式锁

​	如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数 据处理，我们就可以加**分布式锁，锁定此数据，处理完成后释放锁。获取到锁的必须先判断这个数据是否被处理过。**

### 各种唯一约束

#### 1.数据库唯一约束

​	插入数据，应该按照唯一索引进行插入，比如订单号，相同的订单就不可能有两条记录插入。 我们在数据库层面防止重复.

​	**这个机制是利用了数据库的主键唯一约束的特性，**解决了在 insert 场景时幂等问题。**但主键 的要求不是自增的主键，这样就需要业务生成全局唯一的主键。** 如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要
不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。

#### 2.redis set 防重

​	很多数据需要处理，只能被处理一次，比如我们可以**计算数据的MD5 将其放入 redis 的 set**， 每次处理数据，先看这个MD5 是否已经存在，存在就不处理

#### 3.防重表

​	**使用订单号 orderNo 做为去重表的唯一索引，把唯一索引插入去重表，再进行业务操作，且 他们在同一个事务中。**这个保证了重复请求时，因为去重表有唯一约束，导致请求失败，避 免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个 事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。之前说的 redis 防重也算

#### 4.全局请求唯一 id

​	**调用接口时，生成一个唯一 id，redis 将数据保存到集合中（去重），存在即处理过**。 可以使用 nginx 设置每一个请求的唯一 id；
proxy_set_header X-Request-Id $request_id;

# 事务

## 本地事务

一个事务开始，代表以下的所有操作都在同一个连接里面

### 事务的基本性质

- **A :原子性**：一系列的操作整体不可拆分，要么同时成功，要么同时失败
- **C:一致性**：数据在事务的前后，业务整体一致。
- **I :隔离性**：事务之间互相隔离。
- **D:持久性**：一旦事务成功，数据一定会落盘在数据库。

### 事务的隔离级别

- **READ UNCOMMITTED（读未提交）**
  - 该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为**脏读**。
- **READ COMMITTED（读提交）**
  - 一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，**此现象称为不可重 复读问题**
  - **Oracle 和 SQL Server 的默认隔离级别。**
- **REPEATABLE READ（可重复读）**
  - **该隔离级别是 MySQL 默认的隔离级别**，在同一个事务里，select 的结果是事务开始时时间 点的状态，因此，同样的 select 操作读到的结果会是一致的，但是，**会有幻读现象**。
  - MySQL的 InnoDB 引擎可以通过 next-key locks 机制（参考下文"行锁的算法"一节）来避免幻读。
- **SERIALIZABLE（序列化）**
  - 在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式 加一把读共享锁，
  - **从而避免了脏读、不可重读复读和幻读问题。**

### 事务的传播行为

- PROPAGATION  **REQUIRED**：**如果当前没有事务，就创建一个新事务，如果当前存在事务， 就加入该事务，该设置是最常用的设置。** 
- PROPAGATION  **REQUIRES_NEW**：**创建新事务，无论当前存不存在事务，都创建新事务.**
- PROPAGATION  __**NOT_SUPPORTED**：以非事务方式执行操作，如果当前存在事务，就把当 前事务挂起。__
- PROPAGATION  **SUPPORTS**：**支持当前事务，如果当前存在事务，就加入该事务，如果当 前不存在事务，就以非事务执行。**
- PROPAGATION  _**MANDATORY**：支持当前事务，如果当前存在事务，就加入该事务，如果 当前不存在事务，就抛出异常。_
- PROPAGATION  **NEVER**：以非事务方式执行，如果当前存在事务，则抛出异常。
- PROPAGATION  **NESTED**：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与 PROPAGATION_REQUIRED 类似的操作。

### SpringBoot 本地事务关键点

#### 事务的自动配置

- **TransactionAutoConfiguration**

#### 事务的失效问题

​	**同一个对象内事务方法互调默认失效，原因 绕过了代理对象，事务使用代理对象来控制的**

​	在同一个类里面，编写两个方法，内部调用的时候，会导致被调用方法独立设置的事务设置失效。原因是没有用到代理对象的缘故。

​	这种调用就像是将被调用的方法代码卸载方法内部, 如果想使用被调用方法的独立事务设置则需要做一些特殊配置;

##### **解决：使用代理对象来调用事务方法**

1. **导入 spring-boot-starter-aop**
2. **@EnableTransactionManagement(proxyTargetClass = true)**
3. **@EnableAspectJAutoProxy(exposeProxy=true)**
4. **AopContext.currentProxy() 调用方法** 
   1. **获取当前类对象, 获取到的返回值可以直接转换为当前类的类型**

```java
1）、引入aop-starter;spring-boot-starter-aop；默认引入了aspectj

2）、@EnableAspectJAutoProxy(exposeProxy = true)；注解在类上
    //开启 aspectj 动态代理功能。以后所有的动态代理都是aspectj创建的（即使没有接口也可以创建动态代理）。

//对外暴露代理对象
3）、本类互调用调用对象
    OrderServiceImpl orderService = (OrderServiceImpl) AopContext.currentProxy();
	//将返回值类型强转为当前类的类型,可以放心强转
    orderService.b(); //调用统一对象的其他方法
    orderService.c();
```



## 分布式事务

### CAP 定理与BASE 理论

#### CAP 定理

CAP 原则又称 CAP 定理，指的是在一个分布式系统中

- **一致性**（Consistency）：
  - 在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访 问同一份最新的数据副本）
  - 此处一致性是强一致性
- **可用性**（Availability） 
  - 在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据 更新具备高可用性）
- **分区容错性**（Partition tolerance） 
  - 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。
  - 分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务 器放在美国，这就是两个区，它们之间可能无法通信。

**CAP 原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。**

 **一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们， 剩下的 C 和 A 无法同时做到**
分布式系统中实现一致性的 **raft 算法、paxos** 

 [raft算法官方文档](http://thesecretlivesofdata.com/raft/)

#### 面临的问题

​	对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所 以节点故障、网络故障是常态，而且要保证服务可用性达到 99.99999%（N 个 9），即**保证P 和 A(分区容错性和一致性)，舍弃 C(可用性)。**

#### BASE 理论

是对 CAP 理论的延伸，思想是即使无法做到强一致性（**CAP 的一致性就是强一致性**），**但可 以采用适当的采取弱一致性，即最终一致性。**

**柔性事务使用的是BASE理论**

#### BASE 是什么:

- **基本可用（Basically Available）** BA

  - ***基本可用是指分布式系统在出现故障的时候，允许损失部分可用性（例如响应时间、 功能上的可用性），允许损失部分可用性。需要注意的是，基本可用绝不等价于系 统不可用。***
  - **响应时间上的损失**：正常情况下搜索引擎需要在 0.5 秒之内返回给用户相应的 查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询 结果的响应时间增加到了 1~2 秒。
  - **功能上的损失**：购物网站在购物高峰（如双十一）时，为了保护系统的稳定性， 部分消费者可能会被引导到一个降级页面。

- **软状态（ Soft State）** S

  - **软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性**。分布式存储中一般一份数据会有多个副本，
  - ***允许不同副本同步的延时就是软状态的体 现。mysql replication 的异步复制也是一种体现。***

- **最终一致性（ Eventual Consistency）**E

  -  ***最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。***
  -  ***弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。***

  

#### 强一致性、弱一致性、最终一致性

​	从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了 不同的一致性。

- 对于关系型数据库，**要求更新过的数据能被后续的访问都能看到，这是强一 致性。**
- 如果**能容忍后续的部分或者全部访问不到，则是弱一致性**。
- 如果**经过一段时间后要求能访问到更新后的数据，则是最终一致性**

### 分布式事务解决方案

#### 2PC模式  二阶段提交

数据库支持的 2PC【2 phase commit 二阶提交】，又叫做 XA Transactions。 MySQL 从 5.5 版本开始支持，SQL Server 2005 开始支持，Oracle 7 开始支持。
其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段：

- 第一阶段：**事务协调器要求每个涉及到事务的数据库预提交(precommit)此操作，并反映是 否可以提交.** 
- 第二阶段：**事务协调器要求每个数据库提交数据。 其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。**



- XA **协议比较简单**，而且一旦商业数据库实现了 XA 协议，使用分布式事务的成本也比较 低。
- XA **性能不理想**，特别是在交易下单链路，往往并发量很高，XA 无法满足高并发场景 
- XA 目前在商业数据库支持的比较理想，**在 mysql 数据库中支持的不太理想**，mysql 的 XA 实现，没有记录 prepare 阶段日志，主备切换回导致主库与备库数据不一致。
- 许多 nosql 也没有支持 XA，这让 XA 的应用场景变得非常狭隘。 
- 也有 3PC，引入了超时机制（无论协调者还是参与者，在向对方发送请求后，若长时间未收到回应则做出相应处理）



![image-20210128142651687](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210128142651.png)

#### 柔性事务-TCC 事务补偿型方案

- **刚性事务：遵循 ACID 原则，强一致性。** 
- **柔性事务：遵循 BASE 理论，最终一致性；**
  - 与刚性事务不同，***柔性事务允许一定时间内，不同节点的数据不一致，但要求最终一致。***

1. 一阶段 **prepare** 行为：调用 自定义 的 prepare 逻辑。 
2. 二阶段 **commit** 行为：调用 自定义 的 commit 逻辑。 
3. 二阶段 **rollback** 行为：调用 自定义 的 rollback 逻辑。
   ***所谓 TCC 模式，是指支持把 自定义 的分支事务纳入到全局事务的管理中。***

这种实现方式需要我们编写对应逻辑的代码, 然后在不同的阶段被调用;

<img src="https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210128143243.png" alt="image-20210128143243701" style="zoom: 80%;" />

![image-20210128143302476](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210128143302.png)



#### 柔性事务-最大努力通知型方案

​	**按规律进行通知，不保证数据一定能通知成功，但会提供可查询操作接口进行核对。**这种 方案主要用在与第三方系统通讯时，比如：调用微信或支付宝支付后的支付结果通知。

**这种 方案也是结合MQ进行实现，例如：通过MQ 发送 http 请求，设置最大通知次数。达到通 知次数后即不再通知。**
案例：**银行通知、商户通知等**（各大交易业务平台间的商户通知：多次通知、查询校对、对账文件），支付宝的支付成功异步回调



#### 柔性事务-可靠消息+最终一致性方案（异步确保型）

实现：**业务处理服务 在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只 记录消息数据，而不是真正的发送。**

​			**业务处理服务在业务事务提交之后，向实时消息服务确 认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。**
防止消息丢失：

```
/*
	1.做好消息确认机制（pulisher，consumer【手动ack】） 
	2、每一个发送的消息都在数据库做好记录。定期将失败的消息再次发送一遍
*/
```



## 分布式事务中间件Seata

### SEATA 的分布式交易解决方案

- **TC** (Transaction Coordinator) - **事务协调者**
  - 维护全局和分支事务的状态，驱动全局事务提交或回滚。
- **TM** (Transaction Manager) - **事务管理器**
  - 定义全局事务的范围：开始全局事务、提交或回滚全局事务。

- **RM** (Resource Manager) - **资源管理器**
  - 管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。

![image-20210128145302101](https://jianjiandawang.oss-cn-shanghai.aliyuncs.com/Typora/20210128145302.png)

### Seata控制分布式事务使用

[SEATA官方文档](http://seata.io/zh-cn/docs/user/quickstart.html)    [快速配置GitHub参考文档(详细)](https://github.com/seata/seata-samples/blob/master/doc/quick-integration-with-spring-cloud.md)

**这种方式类似于2PC的实现,在高并发情况下性能不佳;**

- `@GlobalTransactional` 注解在业务主方法上: 主方法与小方法都需要再开启`@Transactional`

- 创建 **UNDO_LOG** 表 ; SEATA AT 模式需要 `UNDO_LOG` 表

  ```mysql
  -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log
  CREATE TABLE `undo_log` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `branch_id` bigint(20) NOT NULL,
    `xid` varchar(100) NOT NULL,
    `context` varchar(128) NOT NULL,
    `rollback_info` longblob NOT NULL,
    `log_status` int(11) NOT NULL,
    `log_created` datetime NOT NULL,
    `log_modified` datetime NOT NULL,
    `ext` varchar(100) DEFAULT NULL,
    PRIMARY KEY (`id`),
    UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
  ```

- 从 [Seata事务协调器](https://github.com/seata/seata/releases),下载服务器软件包，将其解压缩。进行配置

- 创建一个代理的数据源

```java
@Configuration
public class SeataConfig {

    @Autowired
    DataSourceProperties dataSourceProperties;

    @Bean
    public DataSource proxyDataSource(DataSourceProperties dataSourceProperties){
        //参考源码DataSourceAutoConfiguration中Hikari创建一个数据源
        HikariDataSource dataSource = dataSourceProperties.initializeDataSourceBuilder().type(HikariDataSource.class).build();
        if (StringUtils.hasText(dataSourceProperties.getName())) {
            dataSource.setPoolName(dataSourceProperties.getName());
        }
        // seata包下的类, 将dataSource包装为代理数据源
        return new DataSourceProxy(dataSource);
    }
}
```

- 整合SpringBoot
  - 导入依赖 `spring-cloud-starter-alibaba-seata  `
    - 自动导入了seata-all-0.7.1 此处版本不一定,根据版本号下载对应版本的 TC事务协调器
  - 解压并启动seata-server；TC事务协调器
    - 主要修改 **registry.conf: 注册中心配置； 修改registry type=nacos**
    - file.conf： [等其他配置文件如需修改参考](http://seata.io/zh-cn/docs/user/configurations.html)
  - **所有想要用到分布式事务的微服务使用 seata `DataSourceProxy `代理自己的数据源**
  - 每个微服务，都必须导入
    *              **registry.conf  file.conf**   复制到配置文件目录下
    *              **修改配置 file.conf  **
                    *              将vgroup_mapping.my_test_tx_group 修改为 **`vgroup_mapping.{application.name}-fescar-service-group = "default"`**   此处`{application.name}`为当前服务名
  - 启动测试分布式事务
  - 给分布式大事务的入口标注`@GlobalTransactional`
  - 每一个远程的小事务用 `@Transactional`
